{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup MediaPipe con Videos Reales del Equipo\n",
        "**Sistema de Anotaci√≥n de Video - Entrega 1**\n",
        "\n",
        "Este notebook permite subir y procesar videos reales grabados por el equipo para entrenar nuestro clasificador de actividades humanas.\n",
        "\n",
        "## Plan de Grabaci√≥n del Equipo:\n",
        "**Total objetivo: 30 videos (10 videos por persona)**\n",
        "\n",
        "### Distribuci√≥n por persona:\n",
        "- **Juan Esteban (P001)**: 10 videos (2 por actividad)\n",
        "- **Juan David (P002)**: 10 videos (2 por actividad)  \n",
        "- **Tomas (P003)**: 10 videos (2 por actividad)\n",
        "\n",
        "### 5 Actividades a grabar:\n",
        "1. **Caminar hacia la c√°mara** (15-20 segundos)\n",
        "2. **Caminar de regreso** (alej√°ndose) (15-20 segundos)\n",
        "3. **Girar** (rotaci√≥n completa) (10-15 segundos)\n",
        "4. **Sentarse** (de pie ‚Üí sentado) (8-12 segundos)\n",
        "5. **Ponerse de pie** (sentado ‚Üí de pie) (8-12 segundos)\n",
        "\n"
      ],
      "metadata": {
        "id": "tUrijExzJvN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe opencv-python matplotlib seaborn pandas numpy tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fZcgnpviJ3Gm",
        "outputId": "2d0aa4ff-9925-41b1-ee83-c46392d06121"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.12/dist-packages (0.10.21)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.25.8)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5y7HiXsgJoDT",
        "outputId": "79ab4cd0-4f2f-4b73-ddc1-f96984f3913b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Todas las dependencias instaladas correctamente\n",
            "üì¶ MediaPipe version: 0.10.21\n",
            "üì¶ OpenCV version: 4.11.0\n"
          ]
        }
      ],
      "source": [
        "# Verificar instalaci√≥n\n",
        "import mediapipe as mp\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import os\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import shutil\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output, HTML, display\n",
        "\n",
        "print(\"‚úÖ Todas las dependencias instaladas correctamente\")\n",
        "print(f\"üì¶ MediaPipe version: {mp.__version__}\")\n",
        "print(f\"üì¶ OpenCV version: {cv2.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuraci√≥n del proyecto con videos reales del equipo\n",
        "PROJECT_CONFIG = {\n",
        "    'activities': [\n",
        "        'caminar_hacia',\n",
        "        'caminar_regreso',\n",
        "        'girar',\n",
        "        'sentarse',\n",
        "        'ponerse_pie'\n",
        "    ],\n",
        "    'team_members': {\n",
        "        'P001': 'Juan Esteban Ruiz',\n",
        "        'P002': 'Juan David Quintero',\n",
        "        'P003': 'Tomas Quintero'\n",
        "    },\n",
        "    'video_requirements': {\n",
        "        'total_target': 30,  # 10 por persona\n",
        "        'per_person': 10,    # 2 por actividad\n",
        "        'per_activity': 6,   # 2 por persona √ó 3 personas\n",
        "        'format': ['mp4', 'mov', 'avi'],\n",
        "        'min_duration': 8,   # segundos\n",
        "        'max_duration': 25,  # segundos\n",
        "        'min_resolution': '720p'\n",
        "    },\n",
        "    'recording_guidelines': {\n",
        "        'orientation': 'horizontal',\n",
        "        'lighting': 'buena iluminaci√≥n natural',\n",
        "        'background': 'fondo despejado',\n",
        "        'distance': '2-3 metros de la c√°mara',\n",
        "        'stability': 'c√°mara fija (no mano alzada)'\n",
        "    },\n",
        "    'mediapipe_config': {\n",
        "        'model_complexity': 1,\n",
        "        'min_detection_confidence': 0.7,\n",
        "        'min_tracking_confidence': 0.5\n",
        "    }\n",
        "}\n",
        "\n",
        "# Crear estructura de directorios\n",
        "def create_project_structure():\n",
        "    \"\"\"Crear la estructura de directorios del proyecto\"\"\"\n",
        "    dirs = ['data/videos', 'data/landmarks', 'data/metadata', 'data/raw_uploads']\n",
        "\n",
        "    for dir_path in dirs:\n",
        "        Path(dir_path).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for activity in PROJECT_CONFIG['activities']:\n",
        "        Path(f\"data/videos/{activity}\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(\"‚úÖ Estructura de directorios creada\")\n",
        "    print(\"üìÅ Carpetas preparadas para cada actividad\")\n",
        "\n",
        "create_project_structure()\n",
        "\n",
        "print(f\"\\nüë• EQUIPO DEL PROYECTO:\")\n",
        "for member_id, name in PROJECT_CONFIG['team_members'].items():\n",
        "    print(f\"   {member_id}: {name}\")\n",
        "\n",
        "print(f\"\\nüéØ OBJETIVO: {PROJECT_CONFIG['video_requirements']['total_target']} videos reales del equipo\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PboX4DAtKSzE",
        "outputId": "75232130-44dc-47dc-d41f-5c731734caf6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Estructura de directorios creada\n",
            "üìÅ Carpetas preparadas para cada actividad\n",
            "\n",
            "üë• EQUIPO DEL PROYECTO:\n",
            "   P001: Juan Esteban Ruiz\n",
            "   P002: Juan David Quintero\n",
            "   P003: Tomas Quintero\n",
            "\n",
            "üéØ OBJETIVO: 30 videos reales del equipo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MOSTRAR INSTRUCCIONES DETALLADAS DE GRABACI√ìN\n",
        "def show_recording_instructions():\n",
        "    \"\"\"Mostrar instrucciones completas de grabaci√≥n\"\"\"\n",
        "\n",
        "    print(\"üì± INSTRUCCIONES COMPLETAS DE GRABACI√ìN\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    print(\"\\nüé• CONFIGURACI√ìN T√âCNICA:\")\n",
        "    print(f\"   üìê Orientaci√≥n: {PROJECT_CONFIG['recording_guidelines']['orientation'].upper()}\")\n",
        "    print(f\"   üí° Iluminaci√≥n: {PROJECT_CONFIG['recording_guidelines']['lighting']}\")\n",
        "    print(f\"   üé≠ Fondo: {PROJECT_CONFIG['recording_guidelines']['background']}\")\n",
        "    print(f\"   üìè Distancia: {PROJECT_CONFIG['recording_guidelines']['distance']}\")\n",
        "    print(f\"   üì∏ Estabilidad: {PROJECT_CONFIG['recording_guidelines']['stability']}\")\n",
        "\n",
        "    print(f\"\\nüìã ESPECIFICACIONES T√âCNICAS:\")\n",
        "    print(f\"   üé¨ Resoluci√≥n m√≠nima: {PROJECT_CONFIG['video_requirements']['min_resolution']}\")\n",
        "    print(f\"   ‚è±Ô∏è Duraci√≥n: {PROJECT_CONFIG['video_requirements']['min_duration']}-{PROJECT_CONFIG['video_requirements']['max_duration']} segundos\")\n",
        "    print(f\"   üì¶ Formatos: {', '.join(PROJECT_CONFIG['video_requirements']['format'])}\")\n",
        "\n",
        "    activities_instructions = {\n",
        "        'caminar_hacia': {\n",
        "            'setup': 'Persona empieza a 4-5 metros de la c√°mara',\n",
        "            'action': 'Camina normalmente hacia la c√°mara',\n",
        "            'duration': '15-20 segundos',\n",
        "            'tips': ['Velocidad natural', 'Mantener direcci√≥n recta', 'Terminar a 1 metro de c√°mara']\n",
        "        },\n",
        "        'caminar_regreso': {\n",
        "            'setup': 'Persona empieza cerca de la c√°mara (1-2 metros)',\n",
        "            'action': 'Camina alej√°ndose de la c√°mara',\n",
        "            'duration': '15-20 segundos',\n",
        "            'tips': ['Puede caminar de espaldas o de lado', 'Mantener en el frame', 'Velocidad constante']\n",
        "        },\n",
        "        'girar': {\n",
        "            'setup': 'Persona parada en el centro del frame',\n",
        "            'action': 'Realiza rotaci√≥n completa (360¬∞)',\n",
        "            'duration': '10-15 segundos',\n",
        "            'tips': ['Giro en el mismo lugar', 'Velocidad moderada', 'Brazos naturales']\n",
        "        },\n",
        "        'sentarse': {\n",
        "            'setup': 'Persona de pie junto a una silla visible',\n",
        "            'action': 'Se sienta naturalmente',\n",
        "            'duration': '8-12 segundos',\n",
        "            'tips': ['Incluir silla en frame', 'Puede repetir 2-3 veces', 'Movimiento natural']\n",
        "        },\n",
        "        'ponerse_pie': {\n",
        "            'setup': 'Persona sentada en silla visible',\n",
        "            'action': 'Se levanta naturalmente',\n",
        "            'duration': '8-12 segundos',\n",
        "            'tips': ['Levantarse completamente', 'Puede repetir 2-3 veces', 'No quedarse agachado']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    print(f\"\\nüìñ INSTRUCCIONES POR ACTIVIDAD:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for activity, instructions in activities_instructions.items():\n",
        "        print(f\"\\nüé¨ {activity.replace('_', ' ').upper()}:\")\n",
        "        print(f\"   üìç Setup: {instructions['setup']}\")\n",
        "        print(f\"   üéØ Acci√≥n: {instructions['action']}\")\n",
        "        print(f\"   ‚è±Ô∏è Duraci√≥n: {instructions['duration']}\")\n",
        "        print(f\"   üí° Tips:\")\n",
        "        for tip in instructions['tips']:\n",
        "            print(f\"      ‚Ä¢ {tip}\")\n",
        "\n",
        "    print(f\"\\nüìù CONVENCI√ìN DE NOMBRES:\")\n",
        "    print(f\"   P001_caminar_hacia_001.mp4 (Juan Esteban)\")\n",
        "    print(f\"   P002_girar_001.mp4 (Juan David)\")\n",
        "    print(f\"   P003_sentarse_002.mp4 (Tomas)\")\n",
        "    print(f\"   Formato: [PERSONA]_[ACTIVIDAD]_[NUMERO].mp4\")\n",
        "\n",
        "    print(f\"\\n‚ö†Ô∏è CONSEJOS IMPORTANTES:\")\n",
        "    print(f\"   üé• Grabar en HORIZONTAL siempre\")\n",
        "    print(f\"   üë§ Una persona por video\")\n",
        "    print(f\"   üîá No importa el audio\")\n",
        "    print(f\"   üì± Usar tr√≠pode o superficie estable\")\n",
        "    print(f\"   ‚òÄÔ∏è Evitar contra-luz\")\n",
        "    print(f\"   üëï Ropa que contraste con el fondo\")\n",
        "\n",
        "    return activities_instructions\n",
        "\n",
        "# Mostrar instrucciones\n",
        "instructions = show_recording_instructions()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1BzkW6GI-Vs",
        "outputId": "47e90241-85a5-4d72-a606-ec2c0408da6a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì± INSTRUCCIONES COMPLETAS DE GRABACI√ìN\n",
            "============================================================\n",
            "\n",
            "üé• CONFIGURACI√ìN T√âCNICA:\n",
            "   üìê Orientaci√≥n: HORIZONTAL\n",
            "   üí° Iluminaci√≥n: buena iluminaci√≥n natural\n",
            "   üé≠ Fondo: fondo despejado\n",
            "   üìè Distancia: 2-3 metros de la c√°mara\n",
            "   üì∏ Estabilidad: c√°mara fija (no mano alzada)\n",
            "\n",
            "üìã ESPECIFICACIONES T√âCNICAS:\n",
            "   üé¨ Resoluci√≥n m√≠nima: 720p\n",
            "   ‚è±Ô∏è Duraci√≥n: 8-25 segundos\n",
            "   üì¶ Formatos: mp4, mov, avi\n",
            "\n",
            "üìñ INSTRUCCIONES POR ACTIVIDAD:\n",
            "============================================================\n",
            "\n",
            "üé¨ CAMINAR HACIA:\n",
            "   üìç Setup: Persona empieza a 4-5 metros de la c√°mara\n",
            "   üéØ Acci√≥n: Camina normalmente hacia la c√°mara\n",
            "   ‚è±Ô∏è Duraci√≥n: 15-20 segundos\n",
            "   üí° Tips:\n",
            "      ‚Ä¢ Velocidad natural\n",
            "      ‚Ä¢ Mantener direcci√≥n recta\n",
            "      ‚Ä¢ Terminar a 1 metro de c√°mara\n",
            "\n",
            "üé¨ CAMINAR REGRESO:\n",
            "   üìç Setup: Persona empieza cerca de la c√°mara (1-2 metros)\n",
            "   üéØ Acci√≥n: Camina alej√°ndose de la c√°mara\n",
            "   ‚è±Ô∏è Duraci√≥n: 15-20 segundos\n",
            "   üí° Tips:\n",
            "      ‚Ä¢ Puede caminar de espaldas o de lado\n",
            "      ‚Ä¢ Mantener en el frame\n",
            "      ‚Ä¢ Velocidad constante\n",
            "\n",
            "üé¨ GIRAR:\n",
            "   üìç Setup: Persona parada en el centro del frame\n",
            "   üéØ Acci√≥n: Realiza rotaci√≥n completa (360¬∞)\n",
            "   ‚è±Ô∏è Duraci√≥n: 10-15 segundos\n",
            "   üí° Tips:\n",
            "      ‚Ä¢ Giro en el mismo lugar\n",
            "      ‚Ä¢ Velocidad moderada\n",
            "      ‚Ä¢ Brazos naturales\n",
            "\n",
            "üé¨ SENTARSE:\n",
            "   üìç Setup: Persona de pie junto a una silla visible\n",
            "   üéØ Acci√≥n: Se sienta naturalmente\n",
            "   ‚è±Ô∏è Duraci√≥n: 8-12 segundos\n",
            "   üí° Tips:\n",
            "      ‚Ä¢ Incluir silla en frame\n",
            "      ‚Ä¢ Puede repetir 2-3 veces\n",
            "      ‚Ä¢ Movimiento natural\n",
            "\n",
            "üé¨ PONERSE PIE:\n",
            "   üìç Setup: Persona sentada en silla visible\n",
            "   üéØ Acci√≥n: Se levanta naturalmente\n",
            "   ‚è±Ô∏è Duraci√≥n: 8-12 segundos\n",
            "   üí° Tips:\n",
            "      ‚Ä¢ Levantarse completamente\n",
            "      ‚Ä¢ Puede repetir 2-3 veces\n",
            "      ‚Ä¢ No quedarse agachado\n",
            "\n",
            "üìù CONVENCI√ìN DE NOMBRES:\n",
            "   P001_caminar_hacia_001.mp4 (Juan Esteban)\n",
            "   P002_girar_001.mp4 (Juan David)\n",
            "   P003_sentarse_002.mp4 (Tomas)\n",
            "   Formato: [PERSONA]_[ACTIVIDAD]_[NUMERO].mp4\n",
            "\n",
            "‚ö†Ô∏è CONSEJOS IMPORTANTES:\n",
            "   üé• Grabar en HORIZONTAL siempre\n",
            "   üë§ Una persona por video\n",
            "   üîá No importa el audio\n",
            "   üì± Usar tr√≠pode o superficie estable\n",
            "   ‚òÄÔ∏è Evitar contra-luz\n",
            "   üëï Ropa que contraste con el fondo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SISTEMA DE CARGA ORGANIZADA POR ACTIVIDAD\n",
        "class ActivityVideoUploader:\n",
        "    \"\"\"Subir y organizar videos por actividad\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.uploaded_videos = {activity: [] for activity in PROJECT_CONFIG['activities']}\n",
        "        self.upload_log = []\n",
        "\n",
        "    def upload_activity_videos(self, activity):\n",
        "        \"\"\"Subir videos para una actividad espec√≠fica\"\"\"\n",
        "        if activity not in PROJECT_CONFIG['activities']:\n",
        "            print(f\"‚ùå Actividad '{activity}' no v√°lida\")\n",
        "            return\n",
        "\n",
        "        print(f\"üîº SUBIR VIDEOS: {activity.replace('_', ' ').upper()}\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        # Mostrar instrucciones espec√≠ficas para esta actividad\n",
        "        self._show_activity_specific_instructions(activity)\n",
        "\n",
        "        print(f\"\\nüìÅ Sube los videos para '{activity.replace('_', ' ')}':\")\n",
        "        print(f\"   üéØ Esperados: {PROJECT_CONFIG['video_requirements']['per_activity']} videos\")\n",
        "        print(f\"   üë• 2 videos por cada miembro del equipo\")\n",
        "\n",
        "        # Subir archivos\n",
        "        uploaded = files.upload()\n",
        "\n",
        "        if not uploaded:\n",
        "            print(\"‚ùå No se subieron archivos\")\n",
        "            return\n",
        "\n",
        "        return self._process_uploaded_files(uploaded, activity)\n",
        "\n",
        "    def _show_activity_specific_instructions(self, activity):\n",
        "        \"\"\"Mostrar instrucciones espec√≠ficas para una actividad\"\"\"\n",
        "        activity_details = {\n",
        "            'caminar_hacia': \"üë§ Persona camina hacia la c√°mara desde lejos\",\n",
        "            'caminar_regreso': \"üë§ Persona camina alej√°ndose de la c√°mara\",\n",
        "            'girar': \"üîÑ Persona gira 360¬∞ en el mismo lugar\",\n",
        "            'sentarse': \"üí∫ Persona se sienta en una silla\",\n",
        "            'ponerse_pie': \"üö∂ Persona se levanta desde sentado\"\n",
        "        }\n",
        "\n",
        "        print(f\"üìñ {activity_details.get(activity, 'Actividad sin descripci√≥n')}\")\n",
        "\n",
        "    def _process_uploaded_files(self, uploaded, target_activity):\n",
        "        \"\"\"Procesar archivos subidos para una actividad\"\"\"\n",
        "        processed_count = 0\n",
        "        errors = []\n",
        "\n",
        "        print(f\"\\nüóÇÔ∏è PROCESANDO {len(uploaded)} ARCHIVOS...\")\n",
        "\n",
        "        for filename in uploaded.keys():\n",
        "            try:\n",
        "                # Validar formato\n",
        "                file_ext = filename.lower().split('.')[-1]\n",
        "                if file_ext not in PROJECT_CONFIG['video_requirements']['format']:\n",
        "                    errors.append(f\"Formato no v√°lido: {filename}\")\n",
        "                    continue\n",
        "\n",
        "                # Detectar persona del nombre del archivo\n",
        "                person_id = self._detect_person_from_filename(filename)\n",
        "\n",
        "                # Generar nombre estandarizado\n",
        "                video_count = len(self.uploaded_videos[target_activity]) + 1\n",
        "                if person_id:\n",
        "                    new_filename = f\"{person_id}_{target_activity}_{video_count:03d}.{file_ext}\"\n",
        "                else:\n",
        "                    new_filename = f\"TEAM_{target_activity}_{video_count:03d}.{file_ext}\"\n",
        "\n",
        "                # Mover a carpeta correcta\n",
        "                dest_dir = Path(f\"data/videos/{target_activity}\")\n",
        "                dest_path = dest_dir / new_filename\n",
        "\n",
        "                shutil.move(filename, str(dest_path))\n",
        "\n",
        "                # Validar video\n",
        "                validation_result = self._validate_video(dest_path)\n",
        "\n",
        "                if validation_result['valid']:\n",
        "                    self.uploaded_videos[target_activity].append({\n",
        "                        'filename': new_filename,\n",
        "                        'original_name': filename,\n",
        "                        'person_id': person_id,\n",
        "                        'validation': validation_result\n",
        "                    })\n",
        "                    processed_count += 1\n",
        "                    print(f\"   ‚úÖ {filename} ‚Üí {new_filename}\")\n",
        "                else:\n",
        "                    errors.append(f\"Video inv√°lido: {filename} - {validation_result['reason']}\")\n",
        "                    dest_path.unlink()  # Eliminar archivo inv√°lido\n",
        "\n",
        "            except Exception as e:\n",
        "                errors.append(f\"Error procesando {filename}: {str(e)}\")\n",
        "\n",
        "        # Mostrar resultados\n",
        "        print(f\"\\nüìä RESULTADOS DE CARGA - {target_activity.upper()}:\")\n",
        "        print(f\"   ‚úÖ Videos procesados: {processed_count}\")\n",
        "        print(f\"   ‚ùå Errores: {len(errors)}\")\n",
        "        print(f\"   üìä Total en actividad: {len(self.uploaded_videos[target_activity])}\")\n",
        "\n",
        "        if errors:\n",
        "            print(f\"\\n‚ö†Ô∏è ERRORES ENCONTRADOS:\")\n",
        "            for error in errors[:5]:\n",
        "                print(f\"   ‚Ä¢ {error}\")\n",
        "\n",
        "        return processed_count\n",
        "\n",
        "    def _detect_person_from_filename(self, filename):\n",
        "        \"\"\"Detectar persona del nombre del archivo\"\"\"\n",
        "        filename_lower = filename.lower()\n",
        "\n",
        "        # Buscar IDs de persona\n",
        "        for person_id in PROJECT_CONFIG['team_members'].keys():\n",
        "            if person_id.lower() in filename_lower:\n",
        "                return person_id\n",
        "\n",
        "        # Buscar nombres\n",
        "        for person_id, name in PROJECT_CONFIG['team_members'].items():\n",
        "            name_parts = name.lower().split()\n",
        "            if any(part in filename_lower for part in name_parts):\n",
        "                return person_id\n",
        "\n",
        "        return None\n",
        "\n",
        "    def _validate_video(self, video_path):\n",
        "        \"\"\"Validar video b√°sico\"\"\"\n",
        "        try:\n",
        "            cap = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "            if not cap.isOpened():\n",
        "                return {'valid': False, 'reason': 'No se puede abrir el video'}\n",
        "\n",
        "            # Obtener propiedades\n",
        "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "            duration = frame_count / fps if fps > 0 else 0\n",
        "\n",
        "            cap.release()\n",
        "\n",
        "            # Validaciones\n",
        "            if duration < PROJECT_CONFIG['video_requirements']['min_duration']:\n",
        "                return {'valid': False, 'reason': f'Muy corto: {duration:.1f}s'}\n",
        "\n",
        "            if duration > PROJECT_CONFIG['video_requirements']['max_duration']:\n",
        "                return {'valid': False, 'reason': f'Muy largo: {duration:.1f}s'}\n",
        "\n",
        "            if width < 640:  # M√≠nima resoluci√≥n\n",
        "                return {'valid': False, 'reason': f'Resoluci√≥n baja: {width}x{height}'}\n",
        "\n",
        "            return {\n",
        "                'valid': True,\n",
        "                'duration': duration,\n",
        "                'resolution': f\"{width}x{height}\",\n",
        "                'fps': fps\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            return {'valid': False, 'reason': f'Error de validaci√≥n: {str(e)}'}\n",
        "\n",
        "# Crear instancia del uploader\n",
        "uploader = ActivityVideoUploader()\n",
        "print(\"‚úÖ Sistema de carga por actividad configurado\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "689NLcipJGZr",
        "outputId": "5acd1eed-7dc1-48a7-ee6e-22434458d28d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Sistema de carga por actividad configurado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üö∂ SUBIR VIDEOS: CAMINAR HACIA LA C√ÅMARA\n",
        "print(\"üé¨ ACTIVIDAD 1/5: CAMINAR HACIA LA C√ÅMARA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"üìñ RECORDATORIO PARA ESTA ACTIVIDAD:\")\n",
        "print(\"   üë§ Persona empieza lejos (4-5 metros)\")\n",
        "print(\"   üö∂ Camina normalmente hacia la c√°mara\")\n",
        "print(\"   ‚è±Ô∏è Duraci√≥n: 15-20 segundos\")\n",
        "print(\"   üéØ Objetivo: 6 videos (2 por persona)\")\n",
        "\n",
        "print(\"\\nüîº SUBE TODOS LOS VIDEOS DE 'CAMINAR HACIA' A LA VEZ:\")\n",
        "\n",
        "result_1 = uploader.upload_activity_videos('caminar_hacia')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "VvwlhRxxJKDq",
        "outputId": "51e9763d-25ec-4fae-9d75-b9f47efd970b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ ACTIVIDAD 1/5: CAMINAR HACIA LA C√ÅMARA\n",
            "============================================================\n",
            "üìñ RECORDATORIO PARA ESTA ACTIVIDAD:\n",
            "   üë§ Persona empieza lejos (4-5 metros)\n",
            "   üö∂ Camina normalmente hacia la c√°mara\n",
            "   ‚è±Ô∏è Duraci√≥n: 15-20 segundos\n",
            "   üéØ Objetivo: 6 videos (2 por persona)\n",
            "\n",
            "üîº SUBE TODOS LOS VIDEOS DE 'CAMINAR HACIA' A LA VEZ:\n",
            "üîº SUBIR VIDEOS: CAMINAR HACIA\n",
            "==================================================\n",
            "üìñ üë§ Persona camina hacia la c√°mara desde lejos\n",
            "\n",
            "üìÅ Sube los videos para 'caminar hacia':\n",
            "   üéØ Esperados: 6 videos\n",
            "   üë• 2 videos por cada miembro del equipo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9221fb73-9dcb-4cda-a784-48189a4e2bfc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9221fb73-9dcb-4cda-a784-48189a4e2bfc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå No se subieron archivos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# üö∂ SUBIR VIDEOS: CAMINAR DE REGRESO\n",
        "print(\"üé¨ ACTIVIDAD 2/5: CAMINAR DE REGRESO\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"üìñ RECORDATORIO PARA ESTA ACTIVIDAD:\")\n",
        "print(\"   üë§ Persona empieza cerca (1-2 metros)\")\n",
        "print(\"   üö∂ Camina alej√°ndose de la c√°mara\")\n",
        "print(\"   ‚è±Ô∏è Duraci√≥n: 15-20 segundos\")\n",
        "print(\"   üéØ Objetivo: 6 videos (2 por persona)\")\n",
        "\n",
        "print(\"\\nüîº SUBE TODOS LOS VIDEOS DE 'CAMINAR DE REGRESO' A LA VEZ:\")\n",
        "\n",
        "result_2 = uploader.upload_activity_videos('caminar_regreso')\n"
      ],
      "metadata": {
        "id": "DymNKczBJODk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üîÑ SUBIR VIDEOS: GIRAR\n",
        "print(\"üé¨ ACTIVIDAD 3/5: GIRAR\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"üìñ RECORDATORIO PARA ESTA ACTIVIDAD:\")\n",
        "print(\"   üë§ Persona parada en el centro\")\n",
        "print(\"   üîÑ Gira 360¬∞ completo en el mismo lugar\")\n",
        "print(\"   ‚è±Ô∏è Duraci√≥n: 10-15 segundos\")\n",
        "print(\"   üéØ Objetivo: 6 videos (2 por persona)\")\n",
        "\n",
        "print(\"\\nüîº SUBE TODOS LOS VIDEOS DE 'GIRAR' A LA VEZ:\")\n",
        "\n",
        "result_3 = uploader.upload_activity_videos('girar')\n"
      ],
      "metadata": {
        "id": "CYjieJAKJSh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üí∫ SUBIR VIDEOS: SENTARSE\n",
        "print(\"üé¨ ACTIVIDAD 4/5: SENTARSE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"üìñ RECORDATORIO PARA ESTA ACTIVIDAD:\")\n",
        "print(\"   üë§ Persona de pie junto a silla\")\n",
        "print(\"   üí∫ Se sienta naturalmente\")\n",
        "print(\"   ‚è±Ô∏è Duraci√≥n: 8-12 segundos\")\n",
        "print(\"   üéØ Objetivo: 6 videos (2 por persona)\")\n",
        "\n",
        "print(\"\\nüîº SUBE TODOS LOS VIDEOS DE 'SENTARSE' A LA VEZ:\")\n",
        "\n",
        "result_4 = uploader.upload_activity_videos('sentarse')\n"
      ],
      "metadata": {
        "id": "VyozMGi_JTi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üö∂ SUBIR VIDEOS: PONERSE DE PIE\n",
        "print(\"üé¨ ACTIVIDAD 5/5: PONERSE DE PIE\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(\"üìñ RECORDATORIO PARA ESTA ACTIVIDAD:\")\n",
        "print(\"   üë§ Persona sentada en silla\")\n",
        "print(\"   üö∂ Se levanta completamente\")\n",
        "print(\"   ‚è±Ô∏è Duraci√≥n: 8-12 segundos\")\n",
        "print(\"   üéØ Objetivo: 6 videos (2 por persona)\")\n",
        "\n",
        "print(\"\\nüîº SUBE TODOS LOS VIDEOS DE 'PONERSE DE PIE' A LA VEZ:\")\n",
        "\n",
        "result_5 = uploader.upload_activity_videos('ponerse_pie')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "aUdcK9WyJUlK",
        "outputId": "56fd5a22-99d0-4f5b-be5f-334aa09aa033"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ ACTIVIDAD 5/5: PONERSE DE PIE\n",
            "============================================================\n",
            "üìñ RECORDATORIO PARA ESTA ACTIVIDAD:\n",
            "   üë§ Persona sentada en silla\n",
            "   üö∂ Se levanta completamente\n",
            "   ‚è±Ô∏è Duraci√≥n: 8-12 segundos\n",
            "   üéØ Objetivo: 6 videos (2 por persona)\n",
            "\n",
            "üîº SUBE TODOS LOS VIDEOS DE 'PONERSE DE PIE' A LA VEZ:\n",
            "üîº SUBIR VIDEOS: PONERSE PIE\n",
            "==================================================\n",
            "üìñ üö∂ Persona se levanta desde sentado\n",
            "\n",
            "üìÅ Sube los videos para 'ponerse pie':\n",
            "   üéØ Esperados: 6 videos\n",
            "   üë• 2 videos por cada miembro del equipo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-49dd2c1f-4dc6-49f6-ac85-8e5f593c13e9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-49dd2c1f-4dc6-49f6-ac85-8e5f593c13e9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå No se subieron archivos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RESUMEN FINAL Y PROCESAMIENTO MEDIAPIPE\n",
        "class MediaPipeProcessor:\n",
        "    \"\"\"Procesador MediaPipe para videos del equipo\"\"\"\n",
        "\n",
        "    def __init__(self, config=None):\n",
        "        if config is None:\n",
        "            config = PROJECT_CONFIG['mediapipe_config']\n",
        "\n",
        "        self.mp_pose = mp.solutions.pose\n",
        "        self.mp_drawing = mp.solutions.drawing_utils\n",
        "        self.pose = self.mp_pose.Pose(\n",
        "            model_complexity=config['model_complexity'],\n",
        "            min_detection_confidence=config['min_detection_confidence'],\n",
        "            min_tracking_confidence=config['min_tracking_confidence']\n",
        "        )\n",
        "\n",
        "        # Landmarks m√°s relevantes para nuestras actividades\n",
        "        self.relevant_landmarks = [\n",
        "            11, 12,  # Hombros\n",
        "            13, 14,  # Codos\n",
        "            15, 16,  # Mu√±ecas\n",
        "            23, 24,  # Caderas\n",
        "            25, 26,  # Rodillas\n",
        "            27, 28,  # Tobillos\n",
        "            29, 30, 31, 32  # Pies\n",
        "        ]\n",
        "\n",
        "        self.landmark_names = [\n",
        "            'L_shoulder', 'R_shoulder', 'L_elbow', 'R_elbow',\n",
        "            'L_wrist', 'R_wrist', 'L_hip', 'R_hip',\n",
        "            'L_knee', 'R_knee', 'L_ankle', 'R_ankle',\n",
        "            'L_heel', 'R_heel', 'L_foot', 'R_foot'\n",
        "        ]\n",
        "\n",
        "    def process_all_team_videos(self):\n",
        "        \"\"\"Procesar todos los videos del equipo\"\"\"\n",
        "        print(\"‚öôÔ∏è PROCESAMIENTO MEDIAPIPE - VIDEOS DEL EQUIPO\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        total_videos = 0\n",
        "        successful_processing = 0\n",
        "        processing_results = {}\n",
        "\n",
        "        # Contar videos totales primero\n",
        "        for activity in PROJECT_CONFIG['activities']:\n",
        "            activity_dir = Path(f\"data/videos/{activity}\")\n",
        "            if activity_dir.exists():\n",
        "                video_files = list(activity_dir.glob(\"*.mp4\")) + \\\n",
        "                             list(activity_dir.glob(\"*.mov\")) + \\\n",
        "                             list(activity_dir.glob(\"*.avi\"))\n",
        "                total_videos += len(video_files)\n",
        "\n",
        "        print(f\"üé¨ Videos encontrados: {total_videos}\")\n",
        "        print(f\"üéØ Procesando con MediaPipe...\")\n",
        "\n",
        "        # Procesar por actividad\n",
        "        for activity in PROJECT_CONFIG['activities']:\n",
        "            activity_dir = Path(f\"data/videos/{activity}\")\n",
        "\n",
        "            if not activity_dir.exists():\n",
        "                continue\n",
        "\n",
        "            video_files = list(activity_dir.glob(\"*.mp4\")) + \\\n",
        "                         list(activity_dir.glob(\"*.mov\")) + \\\n",
        "                         list(activity_dir.glob(\"*.avi\"))\n",
        "\n",
        "            if not video_files:\n",
        "                print(f\"‚ö†Ô∏è {activity}: Sin videos\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nüé¨ Procesando {activity.replace('_', ' ').title()}: {len(video_files)} videos\")\n",
        "\n",
        "            activity_results = []\n",
        "\n",
        "            for video_path in tqdm(video_files, desc=f\"{activity}\"):\n",
        "                result = self._extract_landmarks_from_video(video_path)\n",
        "\n",
        "                if result and result['detection_rate'] > 60:  # M√≠nimo 60% detecci√≥n\n",
        "                    activity_results.append(result)\n",
        "                    successful_processing += 1\n",
        "\n",
        "                    # Guardar landmarks\n",
        "                    self._save_landmarks_csv(result, video_path, activity)\n",
        "\n",
        "                    print(f\"   ‚úÖ {video_path.name}: {result['detection_rate']:.1f}% detecci√≥n\")\n",
        "                else:\n",
        "                    print(f\"   ‚ùå {video_path.name}: Detecci√≥n insuficiente\")\n",
        "\n",
        "            processing_results[activity] = activity_results\n",
        "\n",
        "        # Resumen final\n",
        "        print(f\"\\nüìä PROCESAMIENTO COMPLETADO:\")\n",
        "        print(f\"   üé• Videos totales: {total_videos}\")\n",
        "        print(f\"   ‚úÖ Procesados exitosamente: {successful_processing}\")\n",
        "        print(f\"   üìà Tasa de √©xito: {(successful_processing/total_videos)*100:.1f}%\")\n",
        "\n",
        "        # Guardar resumen\n",
        "        self._save_processing_summary(processing_results, total_videos, successful_processing)\n",
        "\n",
        "        return processing_results\n",
        "\n",
        "    def _extract_landmarks_from_video(self, video_path):\n",
        "        \"\"\"Extraer landmarks de un video\"\"\"\n",
        "        cap = cv2.VideoCapture(str(video_path))\n",
        "\n",
        "        if not cap.isOpened():\n",
        "            return None\n",
        "\n",
        "        landmarks_sequence = []\n",
        "        frame_count = 0\n",
        "        detection_count = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            results = self._process_frame(frame)\n",
        "            frame_count += 1\n",
        "\n",
        "            if results.pose_landmarks:\n",
        "                detection_count += 1\n",
        "                landmarks_data = []\n",
        "                for idx in self.relevant_landmarks:\n",
        "                    landmark = results.pose_landmarks.landmark[idx]\n",
        "                    landmarks_data.extend([\n",
        "                        landmark.x, landmark.y, landmark.z, landmark.visibility\n",
        "                    ])\n",
        "                landmarks_sequence.append(landmarks_data)\n",
        "            else:\n",
        "                landmarks_sequence.append([np.nan] * (len(self.relevant_landmarks) * 4))\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        detection_rate = (detection_count / frame_count) * 100 if frame_count > 0 else 0\n",
        "\n",
        "        return {\n",
        "            'landmarks': np.array(landmarks_sequence),\n",
        "            'frames_total': frame_count,\n",
        "            'frames_detected': detection_count,\n",
        "            'detection_rate': detection_rate,\n",
        "            'video_path': str(video_path)\n",
        "        }\n",
        "\n",
        "    def _process_frame(self, frame):\n",
        "        \"\"\"Procesar frame con MediaPipe\"\"\"\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.pose.process(rgb_frame)\n",
        "        return results\n",
        "\n",
        "    def _save_landmarks_csv(self, result, video_path, activity):\n",
        "        \"\"\"Guardar landmarks como CSV\"\"\"\n",
        "        landmarks_df = pd.DataFrame(\n",
        "            result['landmarks'],\n",
        "            columns=[f\"{name}_{coord}\" for name in self.landmark_names\n",
        "                    for coord in ['x', 'y', 'z', 'visibility']]\n",
        "        )\n",
        "\n",
        "        # Agregar metadata\n",
        "        landmarks_df['activity'] = activity\n",
        "        landmarks_df['video_file'] = video_path.name\n",
        "        landmarks_df['frame_number'] = range(len(landmarks_df))\n",
        "        landmarks_df['detection_rate'] = result['detection_rate']\n",
        "\n",
        "        csv_path = Path(f\"data/landmarks/{video_path.stem}_landmarks.csv\")\n",
        "        landmarks_df.to_csv(csv_path, index=False)\n",
        "\n",
        "    def _save_processing_summary(self, results, total, successful):\n",
        "        \"\"\"Guardar resumen de procesamiento\"\"\"\n",
        "        summary = {\n",
        "            'processing_date': datetime.now().isoformat(),\n",
        "            'team_members': PROJECT_CONFIG['team_members'],\n",
        "            'total_videos': total,\n",
        "            'successful_processing': successful,\n",
        "            'success_rate': (successful/total)*100 if total > 0 else 0,\n",
        "            'results_by_activity': {\n",
        "                activity: {\n",
        "                    'videos_processed': len(activity_results),\n",
        "                    'avg_detection_rate': np.mean([r['detection_rate'] for r in activity_results]) if activity_results else 0,\n",
        "                    'total_frames': sum([r['frames_total'] for r in activity_results]) if activity_results else 0\n",
        "                }\n",
        "                for activity, activity_results in results.items()\n",
        "            }\n",
        "        }\n",
        "\n",
        "        with open('data/metadata/team_processing_summary.json', 'w') as f:\n",
        "            json.dump(summary, f, indent=2)\n",
        "\n",
        "# Crear procesador y ejecutar\n",
        "processor = MediaPipeProcessor()\n",
        "\n",
        "def run_final_processing():\n",
        "    \"\"\"Ejecutar procesamiento final completo\"\"\"\n",
        "    print(\"üèÅ PROCESAMIENTO FINAL DEL DATASET DEL EQUIPO\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Mostrar resumen de videos cargados\n",
        "    print(\"\\nüìä RESUMEN DE VIDEOS CARGADOS:\")\n",
        "    total_loaded = 0\n",
        "    for activity in PROJECT_CONFIG['activities']:\n",
        "        activity_dir = Path(f\"data/videos/{activity}\")\n",
        "        if activity_dir.exists():\n",
        "            video_count = len(list(activity_dir.glob(\"*.*\")))\n",
        "            total_loaded += video_count\n",
        "            print(f\"   üé¨ {activity.replace('_', ' ').title()}: {video_count} videos\")\n",
        "\n",
        "    print(f\"\\nüìà TOTAL CARGADO: {total_loaded} videos\")\n",
        "    print(f\"üéØ META: {PROJECT_CONFIG['video_requirements']['total_target']} videos\")\n",
        "    print(f\"üìä Progreso: {(total_loaded/PROJECT_CONFIG['video_requirements']['total_target'])*100:.1f}%\")\n",
        "\n",
        "    if total_loaded > 0:\n",
        "        print(f\"\\n‚öôÔ∏è INICIANDO PROCESAMIENTO MEDIAPIPE...\")\n",
        "        results = processor.process_all_team_videos()\n",
        "\n",
        "        print(f\"\\nüéâ ¬°ENTREGA 1 COMPLETADA!\")\n",
        "        print(f\"   üìÅ Videos: data/videos/\")\n",
        "        print(f\"   üìä Landmarks: data/landmarks/\")\n",
        "        print(f\"   üìã Metadata: data/metadata/\")\n",
        "        print(f\"   ‚úÖ Listo para EDA\")\n",
        "\n",
        "        return results\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è No se encontraron videos para procesar\")\n",
        "        return None\n",
        "\n",
        "print(\"‚úÖ Procesador MediaPipe configurado\")\n",
        "print(\"üöÄ Ejecuta: run_final_processing() despu√©s de subir todos los videos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgVYIaaLJZJT",
        "outputId": "6f2d0cb5-71b3-42a0-9c53-35b213a61f5d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Procesador MediaPipe configurado\n",
            "üöÄ Ejecuta: run_final_processing() despu√©s de subir todos los videos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Checklist de Carga de Videos\n",
        "\n",
        "### Progreso por Actividad:\n",
        "- [ ] **Caminar hacia** (6 videos objetivo)\n",
        "- [ ] **Caminar regreso** (6 videos objetivo)\n",
        "- [ ] **Girar** (6 videos objetivo)\n",
        "- [ ] **Sentarse** (6 videos objetivo)\n",
        "- [ ] **Ponerse de pie** (6 videos objetivo)\n",
        "\n",
        "### Distribuci√≥n por Miembro:\n",
        "- [ ] **Juan Esteban (P001)**: 10 videos (2 por actividad)\n",
        "- [ ] **Juan David (P002)**: 10 videos (2 por actividad)\n",
        "- [ ] **Tomas (P003)**: 10 videos (2 por actividad)\n",
        "\n",
        "### Pasos Finales:\n",
        "1. **Ejecutar todas las celdas de carga** (6-10)\n",
        "2. **Verificar que se cargaron todos los videos**\n",
        "3. **Ejecutar**: `run_final_processing()`\n",
        "4. **Resultado**: Dataset completo procesado\n",
        "\n",
        "---\n",
        "**Estado**: Videos reales del equipo listos para an√°lisis\n"
      ],
      "metadata": {
        "id": "FhBVRDN-JdQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üöÄ EJECUTAR PROCESAMIENTO FINAL\n",
        "print(\"üé¨ EJECUTANDO PROCESAMIENTO FINAL...\")\n",
        "final_results = run_final_processing()\n",
        "\n",
        "if final_results:\n",
        "    print(\"\\n‚úÖ DATASET DEL EQUIPO COMPLETADO\")\n",
        "    print(\"üéØ Continuar con: 02_eda_inicial.ipynb\")\n",
        "else:\n",
        "    print(\"\\nüì§ Pendiente: Cargar videos en celdas anteriores\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "id": "Cj234WZtJhXK",
        "outputId": "d18f369d-c354-4dad-9f1a-4dfdea90093f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üé¨ EJECUTANDO PROCESAMIENTO FINAL...\n",
            "üèÅ PROCESAMIENTO FINAL DEL DATASET DEL EQUIPO\n",
            "============================================================\n",
            "\n",
            "üìä RESUMEN DE VIDEOS CARGADOS:\n",
            "   üé¨ Caminar Hacia: 13 videos\n",
            "   üé¨ Caminar Regreso: 13 videos\n",
            "   üé¨ Girar: 13 videos\n",
            "   üé¨ Sentarse: 13 videos\n",
            "   üé¨ Ponerse Pie: 13 videos\n",
            "\n",
            "üìà TOTAL CARGADO: 65 videos\n",
            "üéØ META: 30 videos\n",
            "üìä Progreso: 216.7%\n",
            "\n",
            "‚öôÔ∏è INICIANDO PROCESAMIENTO MEDIAPIPE...\n",
            "‚öôÔ∏è PROCESAMIENTO MEDIAPIPE - VIDEOS DEL EQUIPO\n",
            "============================================================\n",
            "üé¨ Videos encontrados: 65\n",
            "üéØ Procesando con MediaPipe...\n",
            "\n",
            "üé¨ Procesando Caminar Hacia: 13 videos\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "caminar_hacia:   0%|          | 0/13 [00:08<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3116140574.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# üöÄ EJECUTAR PROCESAMIENTO FINAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üé¨ EJECUTANDO PROCESAMIENTO FINAL...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfinal_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_final_processing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfinal_results\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1607442815.py\u001b[0m in \u001b[0;36mrun_final_processing\u001b[0;34m()\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_loaded\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n‚öôÔ∏è INICIANDO PROCESAMIENTO MEDIAPIPE...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_all_team_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nüéâ ¬°ENTREGA 1 COMPLETADA!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1607442815.py\u001b[0m in \u001b[0;36mprocess_all_team_videos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvideo_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"{activity}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_landmarks_from_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'detection_rate'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# M√≠nimo 60% detecci√≥n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1607442815.py\u001b[0m in \u001b[0;36m_extract_landmarks_from_video\u001b[0;34m(self, video_path)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0mframe_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1607442815.py\u001b[0m in \u001b[0;36m_process_frame\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;34m\"\"\"Procesar frame con MediaPipe\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mrgb_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mediapipe/python/solutions/pose.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \"\"\"\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlandmark\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_landmarks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pytype: disable=attribute-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/mediapipe/python/solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    338\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m     \u001b[0;31m# output stream names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}