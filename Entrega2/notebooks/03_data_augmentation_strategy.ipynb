{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation Strategy - Expansi√≥n Inteligente del Dataset\n",
        "**Sistema de Anotaci√≥n de Video - Entrega 2**\n",
        "\n",
        "Este notebook implementa estrategias de augmentation para balancear clases y expandir el dataset.\n",
        "\n",
        "## An√°lisis del EDA:\n",
        "- **Desbalance identificado:** Sentarse (14.1%) vs Girar (23.8%)\n",
        "- **Objetivo:** +2,000 frames adicionales\n",
        "- **Estrategia:** Multi-nivel (SMOTE + Espacial + Temporal + Ruido)\n",
        "\n",
        "## Resultados esperados:\n",
        "- Dataset balanceado (~6,500 frames)\n",
        "- Mejora en robustez del modelo\n",
        "- Validaci√≥n de calidad sint√©tica\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-4zlnziWaLYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 1: Instalaci√≥n y Setup\n",
        "Instalar librer√≠as necesarias para data augmentation.\n"
      ],
      "metadata": {
        "id": "Mz9CMJL4aRXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YauzHxgOM2B2",
        "outputId": "c3428f81-1cff-49f1-9750-7f56e4749baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "‚úÖ Librer√≠as para augmentation cargadas\n",
            "üìä Pandas: 2.2.2\n",
            "üî¢ NumPy: 2.0.2\n",
            "üî¨ Imbalanced-learn: 0.14.0\n"
          ]
        }
      ],
      "source": [
        "# Instalar dependencias para augmentation\n",
        "!pip install pandas numpy matplotlib seaborn scikit-learn imbalanced-learn scipy\n",
        "\n",
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import imblearn # Import imblearn directly\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.interpolate import CubicSpline\n",
        "from pathlib import Path\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Librer√≠as para augmentation cargadas\")\n",
        "print(f\"üìä Pandas: {pd.__version__}\")\n",
        "print(f\"üî¢ NumPy: {np.__version__}\")\n",
        "print(f\"üî¨ Imbalanced-learn: {imblearn.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 2: Cargar Dataset Base\n",
        "Cargar el dataset limpio de la Entrega 1 para an√°lisis de desbalance.\n"
      ],
      "metadata": {
        "id": "pVBAHlEsaVQ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CARGAR DATASET BASE DE ENTREGA 1\n",
        "def load_base_dataset():\n",
        "    \"\"\"Cargar dataset base desde Entrega 1\"\"\"\n",
        "    print(\"üìÇ CARGANDO DATASET BASE DESDE ENTREGA 1\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Ruta relativa desde Entrega2 hacia Entrega1 - Adjusting to load from current directory\n",
        "    landmarks_path = Path(\".\") # Search in the current directory\n",
        "\n",
        "    if not landmarks_path.exists():\n",
        "        print(f\"‚ùå No se encontr√≥: {landmarks_path}\")\n",
        "        print(\"üí° Aseg√∫rate de ejecutar desde Entrega2/notebooks/\")\n",
        "        return None\n",
        "\n",
        "    # Cargar todos los CSVs ending with _landmarks.csv\n",
        "    csv_files = list(landmarks_path.glob(\"*_landmarks.csv\"))\n",
        "    print(f\"üìÅ Archivos encontrados: {len(csv_files)}\")\n",
        "\n",
        "    if not csv_files:\n",
        "        print(\"‚ùå No se encontraron archivos CSV de landmarks en el directorio actual.\")\n",
        "        return None\n",
        "\n",
        "    dataframes = []\n",
        "    for csv_file in csv_files:\n",
        "        df = pd.read_csv(csv_file)\n",
        "        dataframes.append(df)\n",
        "\n",
        "    combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "    # Limpiar datos (remover frames sin detecci√≥n)\n",
        "    landmark_cols = [col for col in combined_df.columns\n",
        "                    if col not in ['activity', 'video_file', 'frame_number']]\n",
        "\n",
        "    # Solo frames con detecci√≥n\n",
        "    df_clean = combined_df[(combined_df[landmark_cols] != 0.0).any(axis=1)].copy()\n",
        "\n",
        "    print(f\"üìä DATASET CARGADO:\")\n",
        "    print(f\"   Total frames: {len(df_clean):,}\")\n",
        "    print(f\"   Videos: {df_clean['video_file'].nunique()}\")\n",
        "    print(f\"   Actividades: {df_clean['activity'].nunique()}\")\n",
        "\n",
        "    # Mostrar distribuci√≥n actual\n",
        "    print(f\"\\nüìà DISTRIBUCI√ìN ACTUAL:\")\n",
        "    activity_counts = df_clean['activity'].value_counts()\n",
        "    for activity, count in activity_counts.items():\n",
        "        pct = count / len(df_clean) * 100\n",
        "        print(f\"   {activity.replace('_', ' ').title()}: {count:,} frames ({pct:.1f}%)\")\n",
        "\n",
        "    balance_ratio = activity_counts.min() / activity_counts.max()\n",
        "    print(f\"\\n‚öñÔ∏è Balance actual: {balance_ratio:.2f}\")\n",
        "\n",
        "    return df_clean\n",
        "\n",
        "# Cargar dataset base\n",
        "base_df = load_base_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FIu9U7EaqX3",
        "outputId": "3ecd743f-2121-4818-d378-e14a293e407c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ CARGANDO DATASET BASE DESDE ENTREGA 1\n",
            "==================================================\n",
            "üìÅ Archivos encontrados: 45\n",
            "üìä DATASET CARGADO:\n",
            "   Total frames: 4,575\n",
            "   Videos: 45\n",
            "   Actividades: 5\n",
            "\n",
            "üìà DISTRIBUCI√ìN ACTUAL:\n",
            "   Girar: 1,089 frames (23.8%)\n",
            "   Caminar Regreso: 1,041 frames (22.8%)\n",
            "   Caminar Hacia: 991 frames (21.7%)\n",
            "   Ponerse Pie: 809 frames (17.7%)\n",
            "   Sentarse: 645 frames (14.1%)\n",
            "\n",
            "‚öñÔ∏è Balance actual: 0.59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 3: An√°lisis de Desbalance\n",
        "Analizar en detalle el desbalance de clases y calcular targets de augmentation.\n"
      ],
      "metadata": {
        "id": "z3drYsopbhfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AN√ÅLISIS DETALLADO DE DESBALANCE\n",
        "def analyze_class_imbalance(df):\n",
        "    \"\"\"Analizar desbalance y calcular targets para augmentation\"\"\"\n",
        "    print(\"‚öñÔ∏è AN√ÅLISIS DETALLADO DE DESBALANCE DE CLASES\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    activity_counts = df['activity'].value_counts()\n",
        "    target_frames = activity_counts.max()  # Usar la clase mayoritaria como target\n",
        "\n",
        "    print(f\"üéØ AN√ÅLISIS ACTUAL:\")\n",
        "    print(f\"   Clase mayoritaria: {activity_counts.index[0]} ({activity_counts.iloc[0]:,} frames)\")\n",
        "    print(f\"   Clase minoritaria: {activity_counts.index[-1]} ({activity_counts.iloc[-1]:,} frames)\")\n",
        "    print(f\"   Ratio balance: {activity_counts.min()/activity_counts.max():.2f}\")\n",
        "\n",
        "    # Calcular cu√°ntos frames necesita cada actividad\n",
        "    augmentation_needed = {}\n",
        "    total_augmentation = 0\n",
        "\n",
        "    print(f\"\\nüìä PLAN DE BALANCEO (Target: {target_frames:,} frames por clase):\")\n",
        "\n",
        "    for activity, current_count in activity_counts.items():\n",
        "        needed = max(0, target_frames - current_count)\n",
        "        augmentation_needed[activity] = needed\n",
        "        total_augmentation += needed\n",
        "\n",
        "        status = \"‚úÖ BALANCEADA\" if needed == 0 else f\"üìà NECESITA +{needed:,}\"\n",
        "        print(f\"   {activity.replace('_', ' ').title()}: {current_count:,} ‚Üí {target_frames:,} ({status})\")\n",
        "\n",
        "    print(f\"\\nüéØ RESUMEN DE AUGMENTATION:\")\n",
        "    print(f\"   Total frames a generar: {total_augmentation:,}\")\n",
        "    print(f\"   Dataset final esperado: {len(df) + total_augmentation:,} frames\")\n",
        "    print(f\"   Incremento: {(total_augmentation/len(df))*100:.1f}%\")\n",
        "\n",
        "    # Estrategia por actividad\n",
        "    print(f\"\\nüìã ESTRATEGIA POR ACTIVIDAD:\")\n",
        "    for activity, needed in augmentation_needed.items():\n",
        "        if needed > 0:\n",
        "            # Distribuir t√©cnicas\n",
        "            smote_frames = min(needed, needed // 2)\n",
        "            spatial_frames = needed // 4\n",
        "            temporal_frames = needed // 4\n",
        "            noise_frames = needed - smote_frames - spatial_frames - temporal_frames\n",
        "\n",
        "            print(f\"\\n   üéØ {activity.replace('_', ' ').title()} (+{needed:,} frames):\")\n",
        "            print(f\"      üîÑ SMOTE: {smote_frames:,} frames\")\n",
        "            print(f\"      üîÄ Rotaci√≥n espacial: {spatial_frames:,} frames\")\n",
        "            print(f\"      ‚è±Ô∏è Interpolaci√≥n temporal: {temporal_frames:,} frames\")\n",
        "            print(f\"      üé≤ Noise injection: {noise_frames:,} frames\")\n",
        "\n",
        "    return augmentation_needed, target_frames\n",
        "\n",
        "# Ejecutar an√°lisis de desbalance\n",
        "if base_df is not None:\n",
        "    aug_needed, target_count = analyze_class_imbalance(base_df)\n",
        "    print(f\"\\n‚úÖ ESTRATEGIA DE AUGMENTATION DEFINIDA\")\n",
        "else:\n",
        "    print(\"‚ùå No hay datos para analizar desbalance\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8of2np6hbXoE",
        "outputId": "c0add92a-424b-45d1-84bd-dfcc3bb45691"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚öñÔ∏è AN√ÅLISIS DETALLADO DE DESBALANCE DE CLASES\n",
            "============================================================\n",
            "üéØ AN√ÅLISIS ACTUAL:\n",
            "   Clase mayoritaria: girar (1,089 frames)\n",
            "   Clase minoritaria: sentarse (645 frames)\n",
            "   Ratio balance: 0.59\n",
            "\n",
            "üìä PLAN DE BALANCEO (Target: 1,089 frames por clase):\n",
            "   Girar: 1,089 ‚Üí 1,089 (‚úÖ BALANCEADA)\n",
            "   Caminar Regreso: 1,041 ‚Üí 1,089 (üìà NECESITA +48)\n",
            "   Caminar Hacia: 991 ‚Üí 1,089 (üìà NECESITA +98)\n",
            "   Ponerse Pie: 809 ‚Üí 1,089 (üìà NECESITA +280)\n",
            "   Sentarse: 645 ‚Üí 1,089 (üìà NECESITA +444)\n",
            "\n",
            "üéØ RESUMEN DE AUGMENTATION:\n",
            "   Total frames a generar: 870\n",
            "   Dataset final esperado: 5,445 frames\n",
            "   Incremento: 19.0%\n",
            "\n",
            "üìã ESTRATEGIA POR ACTIVIDAD:\n",
            "\n",
            "   üéØ Caminar Regreso (+48 frames):\n",
            "      üîÑ SMOTE: 24 frames\n",
            "      üîÄ Rotaci√≥n espacial: 12 frames\n",
            "      ‚è±Ô∏è Interpolaci√≥n temporal: 12 frames\n",
            "      üé≤ Noise injection: 0 frames\n",
            "\n",
            "   üéØ Caminar Hacia (+98 frames):\n",
            "      üîÑ SMOTE: 49 frames\n",
            "      üîÄ Rotaci√≥n espacial: 24 frames\n",
            "      ‚è±Ô∏è Interpolaci√≥n temporal: 24 frames\n",
            "      üé≤ Noise injection: 1 frames\n",
            "\n",
            "   üéØ Ponerse Pie (+280 frames):\n",
            "      üîÑ SMOTE: 140 frames\n",
            "      üîÄ Rotaci√≥n espacial: 70 frames\n",
            "      ‚è±Ô∏è Interpolaci√≥n temporal: 70 frames\n",
            "      üé≤ Noise injection: 0 frames\n",
            "\n",
            "   üéØ Sentarse (+444 frames):\n",
            "      üîÑ SMOTE: 222 frames\n",
            "      üîÄ Rotaci√≥n espacial: 111 frames\n",
            "      ‚è±Ô∏è Interpolaci√≥n temporal: 111 frames\n",
            "      üé≤ Noise injection: 0 frames\n",
            "\n",
            "‚úÖ ESTRATEGIA DE AUGMENTATION DEFINIDA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 4: Implementar SMOTE para Balanceo\n",
        "Aplicar SMOTE (Synthetic Minority Oversampling Technique) para generar datos sint√©ticos de clases minoritarias.\n"
      ],
      "metadata": {
        "id": "I43OvUCwbo9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPLEMENTAR SMOTE PARA BALANCEO DE CLASES\n",
        "class SMOTEAugmentator:\n",
        "    \"\"\"Augmentation usando SMOTE para landmarks\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.smote = SMOTE(\n",
        "            sampling_strategy='auto',  # Balancear autom√°ticamente\n",
        "            random_state=42,\n",
        "            k_neighbors=3  # Reducido para datasets peque√±os\n",
        "        )\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "    def apply_smote(self, df):\n",
        "        \"\"\"Aplicar SMOTE al dataset de landmarks\"\"\"\n",
        "        print(\"üîÑ APLICANDO SMOTE PARA BALANCEO\")\n",
        "        print(\"=\" * 40)\n",
        "\n",
        "        # Preparar datos para SMOTE\n",
        "        landmark_cols = [col for col in df.columns\n",
        "                        if col not in ['activity', 'video_file', 'frame_number']]\n",
        "\n",
        "        X = df[landmark_cols].values\n",
        "        y = self.label_encoder.fit_transform(df['activity'].values)\n",
        "\n",
        "        print(f\"üìä ANTES DE SMOTE:\")\n",
        "        unique, counts = np.unique(y, return_counts=True)\n",
        "        activities = self.label_encoder.inverse_transform(unique)\n",
        "        for activity, count in zip(activities, counts):\n",
        "            print(f\"   {activity.replace('_', ' ').title()}: {count:,} samples\")\n",
        "\n",
        "        # Aplicar SMOTE\n",
        "        try:\n",
        "            X_resampled, y_resampled = self.smote.fit_resample(X, y)\n",
        "\n",
        "            print(f\"\\nüîÑ SMOTE APLICADO EXITOSAMENTE\")\n",
        "            print(f\"üìä DESPU√âS DE SMOTE:\")\n",
        "\n",
        "            unique_res, counts_res = np.unique(y_resampled, return_counts=True)\n",
        "            activities_res = self.label_encoder.inverse_transform(unique_res)\n",
        "\n",
        "            total_original = len(X)\n",
        "            total_augmented = len(X_resampled)\n",
        "\n",
        "            smote_generated = {}\n",
        "            for activity, count_new in zip(activities_res, counts_res):\n",
        "                # Contar originales\n",
        "                original_count = len(df[df['activity'] == activity])\n",
        "                generated = count_new - original_count\n",
        "                smote_generated[activity] = max(0, generated)\n",
        "\n",
        "                print(f\"   {activity.replace('_', ' ').title()}: {original_count:,} ‚Üí {count_new:,} (+{generated:,})\")\n",
        "\n",
        "            print(f\"\\nüìà RESUMEN SMOTE:\")\n",
        "            print(f\"   Frames originales: {total_original:,}\")\n",
        "            print(f\"   Frames despu√©s SMOTE: {total_augmented:,}\")\n",
        "            print(f\"   Frames generados: {total_augmented - total_original:,}\")\n",
        "\n",
        "            # Crear DataFrame con datos aumentados\n",
        "            df_smote = self._create_smote_dataframe(X_resampled, y_resampled, landmark_cols)\n",
        "\n",
        "            return df_smote, smote_generated\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error aplicando SMOTE: {e}\")\n",
        "            return None, None\n",
        "\n",
        "    def _create_smote_dataframe(self, X_resampled, y_resampled, landmark_cols):\n",
        "        \"\"\"Crear DataFrame con datos SMOTE\"\"\"\n",
        "        # Crear DataFrame base\n",
        "        df_smote = pd.DataFrame(X_resampled, columns=landmark_cols)\n",
        "\n",
        "        # A√±adir actividades decodificadas\n",
        "        activities_decoded = self.label_encoder.inverse_transform(y_resampled)\n",
        "        df_smote['activity'] = activities_decoded\n",
        "\n",
        "        # A√±adir metadata sint√©tica\n",
        "        df_smote['video_file'] = [f\"SMOTE_{activity}_{i:04d}.synthetic\"\n",
        "                                 for i, activity in enumerate(activities_decoded)]\n",
        "        df_smote['frame_number'] = range(len(df_smote))\n",
        "        df_smote['augmentation_type'] = 'SMOTE'\n",
        "\n",
        "        return df_smote\n",
        "\n",
        "# Crear augmentador SMOTE\n",
        "smote_augmentator = SMOTEAugmentator()\n",
        "\n",
        "# Aplicar SMOTE\n",
        "if base_df is not None:\n",
        "    df_smote, smote_stats = smote_augmentator.apply_smote(base_df)\n",
        "\n",
        "    if df_smote is not None:\n",
        "        print(f\"\\n‚úÖ SMOTE COMPLETADO\")\n",
        "        print(f\"üéØ Dataset balanceado generado: {len(df_smote):,} frames\")\n",
        "else:\n",
        "    print(\"‚ùå No hay datos base para SMOTE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy247P31b1D8",
        "outputId": "da01b17c-5d27-42dc-d91d-43f33b2b8d63"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ APLICANDO SMOTE PARA BALANCEO\n",
            "========================================\n",
            "üìä ANTES DE SMOTE:\n",
            "   Caminar Hacia: 991 samples\n",
            "   Caminar Regreso: 1,041 samples\n",
            "   Girar: 1,089 samples\n",
            "   Ponerse Pie: 809 samples\n",
            "   Sentarse: 645 samples\n",
            "\n",
            "üîÑ SMOTE APLICADO EXITOSAMENTE\n",
            "üìä DESPU√âS DE SMOTE:\n",
            "   Caminar Hacia: 991 ‚Üí 1,089 (+98)\n",
            "   Caminar Regreso: 1,041 ‚Üí 1,089 (+48)\n",
            "   Girar: 1,089 ‚Üí 1,089 (+0)\n",
            "   Ponerse Pie: 809 ‚Üí 1,089 (+280)\n",
            "   Sentarse: 645 ‚Üí 1,089 (+444)\n",
            "\n",
            "üìà RESUMEN SMOTE:\n",
            "   Frames originales: 4,575\n",
            "   Frames despu√©s SMOTE: 5,445\n",
            "   Frames generados: 870\n",
            "\n",
            "‚úÖ SMOTE COMPLETADO\n",
            "üéØ Dataset balanceado generado: 5,445 frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 5: Augmentation Espacial (Rotaciones)\n",
        "Implementar rotaciones espaciales de landmarks para simular diferentes √°ngulos de c√°mara.\n"
      ],
      "metadata": {
        "id": "1CKm_X3Yb9vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AUGMENTATION ESPACIAL - ROTACIONES PARA ROBUSTEZ\n",
        "class SpatialAugmentator:\n",
        "    \"\"\"Augmentation espacial para mejorar robustez del modelo\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.rotation_angles = [10, -10, 20, -20]  # Rotaciones suaves\n",
        "\n",
        "    def rotate_for_robustness(self, df, samples_per_activity=100):\n",
        "        \"\"\"Aplicar rotaciones para mejorar robustez, no para balanceo\"\"\"\n",
        "        print(\"üîÄ AUGMENTATION ESPACIAL - ROBUSTEZ DEL MODELO\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        print(\"üí° OBJETIVO: Mejorar robustez ante variaciones de √°ngulo de c√°mara\")\n",
        "        print(\"üéØ ESTRATEGIA: Generar variaciones espaciales de muestras existentes\")\n",
        "\n",
        "        augmented_dataframes = []\n",
        "        total_generated = 0\n",
        "\n",
        "        for activity in df['activity'].unique():\n",
        "            activity_data = df[df['activity'] == activity].copy()\n",
        "            activity_generated = 0\n",
        "\n",
        "            print(f\"\\n   üé¨ {activity.replace('_', ' ').title()}:\")\n",
        "\n",
        "            for angle in self.rotation_angles:\n",
        "                # Seleccionar muestra peque√±a para rotar\n",
        "                sample_size = min(samples_per_activity // len(self.rotation_angles), len(activity_data) // 10)\n",
        "\n",
        "                if sample_size > 0:\n",
        "                    sample_data = activity_data.sample(n=sample_size, random_state=42+angle)\n",
        "\n",
        "                    # Aplicar rotaci√≥n\n",
        "                    rotated_data = self._apply_rotation(sample_data, angle, activity)\n",
        "\n",
        "                    if rotated_data is not None:\n",
        "                        augmented_dataframes.append(rotated_data)\n",
        "                        activity_generated += len(rotated_data)\n",
        "                        total_generated += len(rotated_data)\n",
        "\n",
        "                        print(f\"      ‚úÖ Rotaci√≥n {angle:+3d}¬∞: {len(rotated_data):,} frames\")\n",
        "\n",
        "            print(f\"   üìä Total generado: {activity_generated:,} frames\")\n",
        "\n",
        "        if augmented_dataframes:\n",
        "            df_rotated = pd.concat(augmented_dataframes, ignore_index=True)\n",
        "\n",
        "            print(f\"\\nüìä ROTACIONES PARA ROBUSTEZ COMPLETADAS:\")\n",
        "            print(f\"   Total frames adicionales: {total_generated:,}\")\n",
        "            print(f\"   Prop√≥sito: Mejorar invarianza espacial\")\n",
        "\n",
        "            return df_rotated\n",
        "        else:\n",
        "            print(\"‚ö†Ô∏è No se generaron rotaciones\")\n",
        "            return None\n",
        "\n",
        "    def _apply_rotation(self, df, angle_degrees, activity):\n",
        "        \"\"\"Aplicar rotaci√≥n espacial a landmarks\"\"\"\n",
        "        try:\n",
        "            angle_rad = np.radians(angle_degrees)\n",
        "            cos_a = np.cos(angle_rad)\n",
        "            sin_a = np.sin(angle_rad)\n",
        "\n",
        "            rotated_df = df.copy()\n",
        "\n",
        "            # Rotar solo landmarks de torso superior (m√°s efectivo)\n",
        "            landmarks_to_rotate = ['L_shoulder', 'R_shoulder', 'L_elbow', 'R_elbow', 'L_wrist', 'R_wrist']\n",
        "\n",
        "            for landmark in landmarks_to_rotate:\n",
        "                x_col = f\"{landmark}_x\"\n",
        "                y_col = f\"{landmark}_y\"\n",
        "\n",
        "                if x_col in rotated_df.columns and y_col in rotated_df.columns:\n",
        "                    # Centrar coordenadas\n",
        "                    x_centered = rotated_df[x_col] - 0.5\n",
        "                    y_centered = rotated_df[y_col] - 0.5\n",
        "\n",
        "                    # Aplicar rotaci√≥n\n",
        "                    x_rot = x_centered * cos_a - y_centered * sin_a\n",
        "                    y_rot = x_centered * sin_a + y_centered * cos_a\n",
        "\n",
        "                    # Recentrar\n",
        "                    rotated_df[x_col] = np.clip(x_rot + 0.5, 0, 1)\n",
        "                    rotated_df[y_col] = np.clip(y_rot + 0.5, 0, 1)\n",
        "\n",
        "            # Actualizar metadata\n",
        "            rotated_df['video_file'] = [f\"ROT{angle_degrees:+03d}_{original}\" for original in rotated_df['video_file']]\n",
        "            rotated_df['augmentation_type'] = f'spatial_rotation_{angle_degrees}deg'\n",
        "\n",
        "            return rotated_df\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error rotaci√≥n {angle_degrees}¬∞: {e}\")\n",
        "            return None\n",
        "\n",
        "# EJECUTAR ROTACIONES CORREGIDAS\n",
        "spatial_augmentator = SpatialAugmentator()\n",
        "\n",
        "if 'df_smote' in locals() and df_smote is not None:\n",
        "    # Usar datos SMOTE como base para rotaciones\n",
        "    df_rotated = spatial_augmentator.rotate_for_robustness(df_smote, samples_per_activity=100)\n",
        "    print(f\"\\n‚úÖ ROTACIONES DE ROBUSTEZ APLICADAS AL DATASET BALANCEADO\")\n",
        "else:\n",
        "    print(\"‚ùå Primero debe completarse SMOTE\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jqNQp1T8b_cs",
        "outputId": "3ff88786-358d-41ea-c572-4441a679086e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÄ AUGMENTATION ESPACIAL - ROBUSTEZ DEL MODELO\n",
            "==================================================\n",
            "üí° OBJETIVO: Mejorar robustez ante variaciones de √°ngulo de c√°mara\n",
            "üéØ ESTRATEGIA: Generar variaciones espaciales de muestras existentes\n",
            "\n",
            "   üé¨ Caminar Hacia:\n",
            "      ‚úÖ Rotaci√≥n +10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n +20¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -20¬∞: 25 frames\n",
            "   üìä Total generado: 100 frames\n",
            "\n",
            "   üé¨ Girar:\n",
            "      ‚úÖ Rotaci√≥n +10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n +20¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -20¬∞: 25 frames\n",
            "   üìä Total generado: 100 frames\n",
            "\n",
            "   üé¨ Ponerse Pie:\n",
            "      ‚úÖ Rotaci√≥n +10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n +20¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -20¬∞: 25 frames\n",
            "   üìä Total generado: 100 frames\n",
            "\n",
            "   üé¨ Sentarse:\n",
            "      ‚úÖ Rotaci√≥n +10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n +20¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -20¬∞: 25 frames\n",
            "   üìä Total generado: 100 frames\n",
            "\n",
            "   üé¨ Caminar Regreso:\n",
            "      ‚úÖ Rotaci√≥n +10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -10¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n +20¬∞: 25 frames\n",
            "      ‚úÖ Rotaci√≥n -20¬∞: 25 frames\n",
            "   üìä Total generado: 100 frames\n",
            "\n",
            "üìä ROTACIONES PARA ROBUSTEZ COMPLETADAS:\n",
            "   Total frames adicionales: 500\n",
            "   Prop√≥sito: Mejorar invarianza espacial\n",
            "\n",
            "‚úÖ ROTACIONES DE ROBUSTEZ APLICADAS AL DATASET BALANCEADO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 6: Augmentation Temporal (Interpolaci√≥n)\n",
        "Generar frames intermedios usando interpolaci√≥n c√∫bica para crear secuencias m√°s densas.\n"
      ],
      "metadata": {
        "id": "4pmcLI6ygu10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# AUGMENTATION TEMPORAL - INTERPOLACI√ìN C√öBICA (CORREGIDA)\n",
        "class TemporalAugmentator:\n",
        "    \"\"\"Augmentation temporal para secuencias de landmarks\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def interpolate_sequences(self, df, target_frames=300):\n",
        "        \"\"\"Generar frames intermedios por interpolaci√≥n\"\"\"\n",
        "        print(\"‚è±Ô∏è AUGMENTATION TEMPORAL - INTERPOLACI√ìN\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        print(\"üí° OBJETIVO: Crear transiciones m√°s suaves entre frames\")\n",
        "        print(\"üéØ M√âTODO: Interpolaci√≥n c√∫bica en secuencias existentes\")\n",
        "\n",
        "        # Verificar si el dataset tiene actividades\n",
        "        if 'activity' not in df.columns:\n",
        "            print(\"‚ùå No se encontr√≥ columna 'activity'\")\n",
        "            return None\n",
        "\n",
        "        unique_activities = df['activity'].unique()\n",
        "\n",
        "        if len(unique_activities) == 0:\n",
        "            print(\"‚ùå No se encontraron actividades\")\n",
        "            return None\n",
        "\n",
        "        augmented_sequences = []\n",
        "        total_generated = 0\n",
        "\n",
        "        frames_per_activity = target_frames // len(unique_activities)\n",
        "\n",
        "        print(f\"üìä PAR√ÅMETROS:\")\n",
        "        print(f\"   Actividades encontradas: {len(unique_activities)}\")\n",
        "        print(f\"   Target por actividad: {frames_per_activity} frames\")\n",
        "\n",
        "        for activity in unique_activities:\n",
        "            activity_data = df[df['activity'] == activity].copy()\n",
        "            activity_generated = 0\n",
        "\n",
        "            print(f\"\\n   üé¨ {activity.replace('_', ' ').title()}: Target +{frames_per_activity:,} frames\")\n",
        "\n",
        "            # Obtener videos √∫nicos para esta actividad\n",
        "            unique_videos = activity_data['video_file'].unique()\n",
        "            print(f\"      üìπ Videos disponibles: {len(unique_videos)}\")\n",
        "\n",
        "            for video_file in unique_videos:\n",
        "                if activity_generated >= frames_per_activity:\n",
        "                    break\n",
        "\n",
        "                video_sequence = activity_data[activity_data['video_file'] == video_file].copy()\n",
        "                video_sequence = video_sequence.sort_values('frame_number').reset_index(drop=True)\n",
        "\n",
        "                # Solo interpolar videos cortos (necesitan m√°s densidad)\n",
        "                if len(video_sequence) < 100:  # Videos cortos\n",
        "                    interpolated = self._interpolate_video(video_sequence, activity)\n",
        "\n",
        "                    if interpolated is not None:\n",
        "                        new_frames = len(interpolated) - len(video_sequence)\n",
        "                        if new_frames > 0:\n",
        "                            augmented_sequences.append(interpolated)\n",
        "                            activity_generated += new_frames\n",
        "                            total_generated += new_frames\n",
        "\n",
        "                            print(f\"      ‚úÖ {video_file}: {len(video_sequence):,} ‚Üí {len(interpolated):,} (+{new_frames:,})\")\n",
        "                else:\n",
        "                    print(f\"      ‚ûñ {video_file}: {len(video_sequence):,} frames (suficientemente denso)\")\n",
        "\n",
        "            print(f\"   üìä Total generado para {activity}: {activity_generated:,} frames\")\n",
        "\n",
        "        if augmented_sequences:\n",
        "            df_interpolated = pd.concat(augmented_sequences, ignore_index=True)\n",
        "\n",
        "            print(f\"\\nüìä INTERPOLACI√ìN COMPLETADA:\")\n",
        "            print(f\"   Total frames generados: {total_generated:,}\")\n",
        "            print(f\"   Secuencias procesadas: {len(augmented_sequences):,}\")\n",
        "            print(f\"   Prop√≥sito: Transiciones m√°s suaves\")\n",
        "\n",
        "            return df_interpolated\n",
        "        else:\n",
        "            print(f\"\\nüí° NO SE REQUIERE INTERPOLACI√ìN:\")\n",
        "            print(f\"   Todos los videos tienen densidad suficiente (‚â•100 frames)\")\n",
        "            print(f\"   Dataset actual es apropiado para entrenamiento\")\n",
        "            return None\n",
        "\n",
        "    def _interpolate_video(self, video_df, activity):\n",
        "        \"\"\"Interpolar una secuencia de video individual\"\"\"\n",
        "        try:\n",
        "            landmark_cols = [col for col in video_df.columns\n",
        "                           if col not in ['activity', 'video_file', 'frame_number', 'augmentation_type']]\n",
        "\n",
        "            original_length = len(video_df)\n",
        "            # Aumentar 50% la densidad para videos cortos\n",
        "            new_length = int(original_length * 1.5)\n",
        "\n",
        "            # √çndices originales y nuevos\n",
        "            original_idx = np.arange(original_length)\n",
        "            new_idx = np.linspace(0, original_length-1, new_length)\n",
        "\n",
        "            # Datos interpolados\n",
        "            interpolated_data = {}\n",
        "\n",
        "            for col in landmark_cols:\n",
        "                values = video_df[col].values\n",
        "\n",
        "                # Interpolaci√≥n c√∫bica suave\n",
        "                cs = CubicSpline(original_idx, values, extrapolate=False)\n",
        "                interpolated_values = cs(new_idx)\n",
        "\n",
        "                # Validar rangos seg√∫n tipo de coordenada\n",
        "                if col.endswith('_x') or col.endswith('_y'):\n",
        "                    interpolated_values = np.clip(interpolated_values, 0, 1)\n",
        "                elif col.endswith('_visibility'):\n",
        "                    interpolated_values = np.clip(interpolated_values, 0, 1)\n",
        "                elif col.endswith('_z'):\n",
        "                    # Z m√°s permisivo pero limitado\n",
        "                    interpolated_values = np.clip(interpolated_values, -1.5, 1.5)\n",
        "\n",
        "                interpolated_data[col] = interpolated_values\n",
        "\n",
        "            # Crear DataFrame interpolado\n",
        "            df_interp = pd.DataFrame(interpolated_data)\n",
        "            df_interp['activity'] = activity\n",
        "            df_interp['video_file'] = f\"INTERP_{video_df['video_file'].iloc[0]}\"\n",
        "            df_interp['frame_number'] = range(len(df_interp))\n",
        "            df_interp['augmentation_type'] = 'temporal_interpolation'\n",
        "\n",
        "            return df_interp\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error interpolando video: {e}\")\n",
        "            return None\n",
        "\n",
        "# Crear augmentador temporal CORREGIDO\n",
        "temporal_augmentator = TemporalAugmentator()\n",
        "\n",
        "# APLICAR INTERPOLACI√ìN AL DATASET BASE (no SMOTE)\n",
        "if 'base_df' in globals() and base_df is not None:\n",
        "    print(\"üéØ USANDO DATASET BASE PARA INTERPOLACI√ìN\")\n",
        "    df_interpolated = temporal_augmentator.interpolate_sequences(base_df, target_frames=300)\n",
        "\n",
        "    if df_interpolated is not None:\n",
        "        print(f\"\\n‚úÖ INTERPOLACI√ìN TEMPORAL COMPLETADA\")\n",
        "    else:\n",
        "        print(f\"\\nüí° INTERPOLACI√ìN OMITIDA - Dataset tiene densidad apropiada\")\n",
        "else:\n",
        "    print(\"‚ùå No hay dataset base para interpolaci√≥n\")\n",
        "    df_interpolated = None\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bqdeWv6gvwj",
        "outputId": "77177dc5-b875-44eb-b571-5c50ff565d44"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ USANDO DATASET BASE PARA INTERPOLACI√ìN\n",
            "‚è±Ô∏è AUGMENTATION TEMPORAL - INTERPOLACI√ìN\n",
            "==================================================\n",
            "üí° OBJETIVO: Crear transiciones m√°s suaves entre frames\n",
            "üéØ M√âTODO: Interpolaci√≥n c√∫bica en secuencias existentes\n",
            "üìä PAR√ÅMETROS:\n",
            "   Actividades encontradas: 5\n",
            "   Target por actividad: 60 frames\n",
            "\n",
            "   üé¨ Caminar Hacia: Target +60 frames\n",
            "      üìπ Videos disponibles: 9\n",
            "      ‚úÖ caminar_hacia_005.mp4: 95 ‚Üí 142 (+47)\n",
            "      ‚ûñ caminar_hacia_009.mp4: 115 frames (suficientemente denso)\n",
            "      ‚úÖ caminar_hacia_003.mp4: 95 ‚Üí 142 (+47)\n",
            "   üìä Total generado para caminar_hacia: 94 frames\n",
            "\n",
            "   üé¨ Girar: Target +60 frames\n",
            "      üìπ Videos disponibles: 8\n",
            "      ‚ûñ girar_006.mp4: 124 frames (suficientemente denso)\n",
            "      ‚ûñ girar_003.mp4: 122 frames (suficientemente denso)\n",
            "      ‚ûñ girar_007.mp4: 139 frames (suficientemente denso)\n",
            "      ‚ûñ girar_001.mp4: 134 frames (suficientemente denso)\n",
            "      ‚ûñ girar_002.mp4: 130 frames (suficientemente denso)\n",
            "      ‚ûñ girar_005.mp4: 152 frames (suficientemente denso)\n",
            "      ‚ûñ girar_004.mp4: 156 frames (suficientemente denso)\n",
            "      ‚ûñ girar_008.mp4: 132 frames (suficientemente denso)\n",
            "   üìä Total generado para girar: 0 frames\n",
            "\n",
            "   üé¨ Ponerse Pie: Target +60 frames\n",
            "      üìπ Videos disponibles: 10\n",
            "      ‚úÖ ponerse_pie_003.mp4: 79 ‚Üí 118 (+39)\n",
            "      ‚úÖ ponerse_pie_001.mp4: 74 ‚Üí 111 (+37)\n",
            "   üìä Total generado para ponerse_pie: 76 frames\n",
            "\n",
            "   üé¨ Sentarse: Target +60 frames\n",
            "      üìπ Videos disponibles: 8\n",
            "      ‚ûñ sentarse_006.mp4: 107 frames (suficientemente denso)\n",
            "      ‚úÖ sentarse_004.mp4: 79 ‚Üí 118 (+39)\n",
            "      ‚úÖ sentarse_008.mp4: 78 ‚Üí 117 (+39)\n",
            "   üìä Total generado para sentarse: 78 frames\n",
            "\n",
            "   üé¨ Caminar Regreso: Target +60 frames\n",
            "      üìπ Videos disponibles: 10\n",
            "      ‚úÖ caminar_regreso_001.mp4: 92 ‚Üí 138 (+46)\n",
            "      ‚ûñ caminar_regreso_010.mp4: 106 frames (suficientemente denso)\n",
            "      ‚ûñ caminar_regreso_009.mp4: 100 frames (suficientemente denso)\n",
            "      ‚ûñ caminar_regreso_002.mp4: 108 frames (suficientemente denso)\n",
            "      ‚ûñ caminar_regreso_008.mp4: 108 frames (suficientemente denso)\n",
            "      ‚ûñ caminar_regreso_006.mp4: 104 frames (suficientemente denso)\n",
            "      ‚ûñ caminar_regreso_007.mp4: 104 frames (suficientemente denso)\n",
            "      ‚ûñ caminar_regreso_005.mp4: 106 frames (suficientemente denso)\n",
            "      ‚ûñ caminar_regreso_004.mp4: 107 frames (suficientemente denso)\n",
            "      ‚ûñ caminar_regreso_003.mp4: 106 frames (suficientemente denso)\n",
            "   üìä Total generado para caminar_regreso: 46 frames\n",
            "\n",
            "üìä INTERPOLACI√ìN COMPLETADA:\n",
            "   Total frames generados: 294\n",
            "   Secuencias procesadas: 7\n",
            "   Prop√≥sito: Transiciones m√°s suaves\n",
            "\n",
            "‚úÖ INTERPOLACI√ìN TEMPORAL COMPLETADA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Paso 7: Combinar Dataset Final Aumentado\n",
        "Combinar todos los datos aumentados (original + SMOTE + rotaciones + interpolaci√≥n) en dataset final.\n"
      ],
      "metadata": {
        "id": "AW0sWvmLjM58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMBINAR TODOS LOS DATOS AUMENTADOS - VERSI√ìN FINAL\n",
        "def create_final_augmented_dataset():\n",
        "    \"\"\"Combinar todos los datasets aumentados en versi√≥n final\"\"\"\n",
        "    print(\"üîó CREANDO DATASET FINAL AUMENTADO\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    all_dataframes = []\n",
        "    technique_summary = {}\n",
        "\n",
        "    # 1. Datos originales limpios\n",
        "    if 'base_df' in globals() and base_df is not None:\n",
        "        original_data = base_df.copy()\n",
        "        original_data['augmentation_type'] = 'original'\n",
        "        original_data['source'] = 'real_video'\n",
        "        all_dataframes.append(original_data)\n",
        "        technique_summary['original'] = len(original_data)\n",
        "        print(f\"   ‚úÖ Datos originales: {len(original_data):,} frames\")\n",
        "\n",
        "    # 2. Datos SMOTE (sint√©ticos de balanceo)\n",
        "    if 'df_smote' in globals() and df_smote is not None:\n",
        "        # Filtrar solo los sint√©ticos (identificar por nombres de archivo)\n",
        "        smote_data = df_smote[df_smote['video_file'].str.contains('SMOTE_', na=False)].copy()\n",
        "        if not smote_data.empty:\n",
        "            smote_data['source'] = 'smote_synthetic'\n",
        "            all_dataframes.append(smote_data)\n",
        "            technique_summary['SMOTE'] = len(smote_data)\n",
        "            print(f\"   ‚úÖ SMOTE sint√©tico: {len(smote_data):,} frames\")\n",
        "\n",
        "    # 3. Datos rotados (robustez espacial)\n",
        "    if 'df_rotated' in globals() and df_rotated is not None:\n",
        "        rotated_data = df_rotated.copy()\n",
        "        rotated_data['source'] = 'spatial_augmentation'\n",
        "        all_dataframes.append(rotated_data)\n",
        "        technique_summary['spatial_rotation'] = len(rotated_data)\n",
        "        print(f\"   ‚úÖ Rotaciones espaciales: {len(rotated_data):,} frames\")\n",
        "\n",
        "    # 4. Datos interpolados (densidad temporal)\n",
        "    if 'df_interpolated' in globals() and df_interpolated is not None:\n",
        "        interpolated_data = df_interpolated.copy()\n",
        "        interpolated_data['source'] = 'temporal_augmentation'\n",
        "        all_dataframes.append(interpolated_data)\n",
        "        technique_summary['temporal_interpolation'] = len(interpolated_data)\n",
        "        print(f\"   ‚úÖ Interpolaci√≥n temporal: {len(interpolated_data):,} frames\")\n",
        "\n",
        "    if not all_dataframes:\n",
        "        print(\"‚ùå No hay datasets para combinar\")\n",
        "        return None\n",
        "\n",
        "    # Combinar todos los DataFrames\n",
        "    df_master = pd.concat(all_dataframes, ignore_index=True)\n",
        "\n",
        "    print(f\"\\nüìä DATASET MAESTRO CREADO:\")\n",
        "    print(f\"   üìà Total frames: {len(df_master):,}\")\n",
        "    print(f\"   üìπ Videos √∫nicos: {df_master['video_file'].nunique():,}\")\n",
        "    print(f\"   üîß T√©cnicas aplicadas: {len(technique_summary)}\")\n",
        "\n",
        "    # An√°lisis de distribuci√≥n final\n",
        "    print(f\"\\nüéØ DISTRIBUCI√ìN FINAL POR ACTIVIDAD:\")\n",
        "    final_distribution = df_master['activity'].value_counts()\n",
        "\n",
        "    for activity, count in final_distribution.items():\n",
        "        percentage = count / len(df_master) * 100\n",
        "        print(f\"   {activity.replace('_', ' ').title()}: {count:,} frames ({percentage:.1f}%)\")\n",
        "\n",
        "    # Calcular balance final\n",
        "    balance_ratio = final_distribution.min() / final_distribution.max()\n",
        "    balance_improvement = ((balance_ratio - 0.59) / 0.59) * 100\n",
        "\n",
        "    print(f\"\\n‚öñÔ∏è AN√ÅLISIS DE BALANCE:\")\n",
        "    print(f\"   Balance original (EDA): 0.59\")\n",
        "    print(f\"   Balance final: {balance_ratio:.3f}\")\n",
        "    print(f\"   Mejora: {balance_improvement:+.1f}%\")\n",
        "    print(f\"   Evaluaci√≥n: {'‚úÖ EXCELENTE' if balance_ratio > 0.95 else '‚úÖ BUENO' if balance_ratio > 0.85 else 'üìà MEJORADO'}\")\n",
        "\n",
        "    # Distribuci√≥n por fuente de datos\n",
        "    print(f\"\\nüìä DISTRIBUCI√ìN POR FUENTE:\")\n",
        "    source_distribution = df_master['source'].value_counts()\n",
        "    for source, count in source_distribution.items():\n",
        "        percentage = count / len(df_master) * 100\n",
        "        print(f\"   {source.replace('_', ' ').title()}: {count:,} frames ({percentage:.1f}%)\")\n",
        "\n",
        "    return df_master, technique_summary, balance_ratio\n",
        "\n",
        "# Ejecutar combinaci√≥n final\n",
        "final_result = create_final_augmented_dataset()\n",
        "\n",
        "if final_result[0] is not None:\n",
        "    df_complete_augmented, tech_summary, final_balance = final_result\n",
        "    print(f\"\\nüéâ DATASET FINAL AUMENTADO CREADO EXITOSAMENTE\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå Error creando dataset final\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQgZCFEUoxRa",
        "outputId": "cc09e3a7-07fa-4636-d9cd-027c3b0755ec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó CREANDO DATASET FINAL AUMENTADO\n",
            "==================================================\n",
            "   ‚úÖ Datos originales: 4,575 frames\n",
            "   ‚úÖ SMOTE sint√©tico: 5,445 frames\n",
            "   ‚úÖ Rotaciones espaciales: 500 frames\n",
            "   ‚úÖ Interpolaci√≥n temporal: 886 frames\n",
            "\n",
            "üìä DATASET MAESTRO CREADO:\n",
            "   üìà Total frames: 11,406\n",
            "   üìπ Videos √∫nicos: 5,997\n",
            "   üîß T√©cnicas aplicadas: 4\n",
            "\n",
            "üéØ DISTRIBUCI√ìN FINAL POR ACTIVIDAD:\n",
            "   Caminar Hacia: 2,464 frames (21.6%)\n",
            "   Caminar Regreso: 2,368 frames (20.8%)\n",
            "   Girar: 2,278 frames (20.0%)\n",
            "   Ponerse Pie: 2,227 frames (19.5%)\n",
            "   Sentarse: 2,069 frames (18.1%)\n",
            "\n",
            "‚öñÔ∏è AN√ÅLISIS DE BALANCE:\n",
            "   Balance original (EDA): 0.59\n",
            "   Balance final: 0.840\n",
            "   Mejora: +42.3%\n",
            "   Evaluaci√≥n: üìà MEJORADO\n",
            "\n",
            "üìä DISTRIBUCI√ìN POR FUENTE:\n",
            "   Smote Synthetic: 5,445 frames (47.7%)\n",
            "   Real Video: 4,575 frames (40.1%)\n",
            "   Temporal Augmentation: 886 frames (7.8%)\n",
            "   Spatial Augmentation: 500 frames (4.4%)\n",
            "\n",
            "üéâ DATASET FINAL AUMENTADO CREADO EXITOSAMENTE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GUARDAR DATASET MAESTRO FINAL\n",
        "print(\"üíæ GUARDANDO DATASET MAESTRO AUMENTADO\")\n",
        "print(\"=\" * 45)\n",
        "\n",
        "# Crear carpeta\n",
        "os.makedirs('data/augmented', exist_ok=True)\n",
        "\n",
        "# Guardar archivo principal\n",
        "dataset_path = 'data/augmented/landmarks_final_augmented.csv'\n",
        "df_complete_augmented.to_csv(dataset_path, index=False)\n",
        "\n",
        "# Mostrar informaci√≥n\n",
        "file_size = os.path.getsize(dataset_path) / (1024*1024)\n",
        "\n",
        "print(f\"‚úÖ DATASET GUARDADO:\")\n",
        "print(f\"   üìÅ {dataset_path}\")\n",
        "print(f\"   üìä {len(df_complete_augmented):,} frames\")\n",
        "print(f\"   üíΩ {file_size:.1f} MB\")\n",
        "print(f\"   ‚öñÔ∏è Balance: 0.840\")\n",
        "\n",
        "print(f\"\\nüéâ NOTEBOOK 3 - DATA AUGMENTATION COMPLETADO\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKRz1pFrqnRl",
        "outputId": "f9df2114-7b3e-43ea-8df2-1c000a0c791a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üíæ GUARDANDO DATASET MAESTRO AUMENTADO\n",
            "=============================================\n",
            "‚úÖ DATASET GUARDADO:\n",
            "   üìÅ data/augmented/landmarks_final_augmented.csv\n",
            "   üìä 11,406 frames\n",
            "   üíΩ 13.9 MB\n",
            "   ‚öñÔ∏è Balance: 0.840\n",
            "\n",
            "üéâ NOTEBOOK 3 - DATA AUGMENTATION COMPLETADO\n"
          ]
        }
      ]
    }
  ]
}