{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMTRHSRoVt4XZmSN26PrfPM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ============================================\n","# INTERFAZ GRADIO - VERSI√ìN NUMPY 2.x\n","# Notebook: 08_gradio_inference.ipynb\n","# ============================================\n","\n","print(\"üì¶ INSTALANDO DEPENDENCIAS...\")\n","print(\"=\" * 60)\n","\n","# ESTRATEGIA: Usar NumPy 2.x (compatible con los .pkl generados)\n","# Ignorar warnings de MediaPipe (funcionar√° de todas formas)\n","\n","# Desinstalar conflictos\n","!pip uninstall -y numpy mediapipe opencv-python opencv-python-headless -q\n","\n","# Instalar NumPy 2.x (compatible con los .pkl)\n","!pip install numpy>=2.0 -q\n","\n","# Instalar MediaPipe (advertir√° pero funcionar√°)\n","!pip install mediapipe==0.10.21 --no-deps -q\n","!pip install opencv-python==4.8.1.78 -q\n","!pip install attrs flatbuffers absl-py protobuf>=3.20 -q\n","\n","# Otras dependencias\n","!pip install matplotlib pandas tqdm -q\n","!pip install gradio -q\n","\n","print(\"‚úÖ Dependencias instaladas\")\n","print(\"‚ö†Ô∏è  Ignorar warnings de compatibilidad - el c√≥digo funcionar√°\\n\")\n","\n","# ============================================\n","# IMPORTS\n","# ============================================\n","\n","print(\"üìö IMPORTANDO LIBRER√çAS...\")\n","\n","import gradio as gr\n","import cv2\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from datetime import datetime\n","import os\n","import joblib\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","# MediaPipe import especial\n","import sys\n","sys.path.insert(0, '/usr/local/lib/python3.12/dist-packages')\n","\n","try:\n","    import mediapipe as mp\n","    print(f\"‚úÖ MediaPipe: {mp.__version__}\")\n","except ImportError as e:\n","    print(f\"‚ö†Ô∏è  Reinstalando MediaPipe...\")\n","    !pip install mediapipe==0.10.21 --force-reinstall -q\n","    import mediapipe as mp\n","\n","print(f\"‚úÖ NumPy: {np.__version__}\")\n","print(f\"‚úÖ OpenCV: {cv2.__version__}\\n\")\n","\n","# ============================================\n","# CARGAR MODELO Y TRANSFORMERS\n","# ============================================\n","\n","print(\"ü§ñ CARGANDO MODELO Y TRANSFORMERS...\")\n","print(\"=\" * 60)\n","\n","# Verificar archivos\n","required_files = {\n","    'Modelo': 'best_model_mlp.pkl',\n","    'Scaler': 'scaler.pkl',\n","    'PCA': 'pca.pkl',\n","    'Encoder': 'label_encoder.pkl'\n","}\n","\n","print(f\"\\nüìÇ VERIFICANDO ARCHIVOS:\")\n","for name, filepath in required_files.items():\n","    if os.path.exists(filepath):\n","        size_kb = os.path.getsize(filepath) / 1024\n","        print(f\"   ‚úÖ {name}: {filepath} ({size_kb:.2f} KB)\")\n","    else:\n","        print(f\"   ‚ùå {name}: {filepath} NO ENCONTRADO\")\n","        raise FileNotFoundError(f\"{filepath} no encontrado\")\n","\n","# Cargar con NumPy 2.x (ahora deber√≠a funcionar)\n","print(f\"\\nüîÑ CARGANDO COMPONENTES...\")\n","\n","model = joblib.load('best_model_mlp.pkl')\n","print(f\"   ‚úÖ Modelo MLP cargado\")\n","\n","scaler = joblib.load('scaler.pkl')\n","print(f\"   ‚úÖ Scaler cargado\")\n","\n","pca = joblib.load('pca.pkl')\n","print(f\"   ‚úÖ PCA cargado ({pca.n_components_} componentes)\")\n","\n","label_encoder = joblib.load('label_encoder.pkl')\n","print(f\"   ‚úÖ Label Encoder cargado ({len(label_encoder.classes_)} clases)\")\n","\n","print(f\"\\nüè∑Ô∏è  CLASES DETECTABLES:\")\n","for i, activity in enumerate(label_encoder.classes_):\n","    print(f\"   {i}. {activity.replace('_', ' ').title()}\")\n","\n","print(f\"\\n‚úÖ MODELO LISTO\\n\")\n","\n","# ============================================\n","# CONFIGURAR MEDIAPIPE\n","# ============================================\n","\n","print(\"üé• CONFIGURANDO MEDIAPIPE...\")\n","\n","mp_pose = mp.solutions.pose\n","mp_drawing = mp.solutions.drawing_utils\n","mp_drawing_styles = mp.solutions.drawing_styles\n","\n","pose = mp_pose.Pose(\n","    static_image_mode=False,\n","    model_complexity=1,\n","    smooth_landmarks=True,\n","    min_detection_confidence=0.5,\n","    min_tracking_confidence=0.5\n",")\n","\n","print(\"‚úÖ MediaPipe configurado\\n\")\n","\n","# ============================================\n","# FUNCIONES DE PROCESAMIENTO\n","# ============================================\n","\n","print(\"üîß DEFINIENDO FUNCIONES...\")\n","\n","def extract_landmarks(frame):\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    results = pose.process(frame_rgb)\n","\n","    annotated_frame = frame.copy()\n","    if results.pose_landmarks:\n","        mp_drawing.draw_landmarks(\n","            annotated_frame,\n","            results.pose_landmarks,\n","            mp_pose.POSE_CONNECTIONS,\n","            landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style()\n","        )\n","\n","        landmarks = []\n","        for landmark in results.pose_landmarks.landmark:\n","            landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n","\n","        return np.array(landmarks, dtype=np.float32), annotated_frame\n","\n","    return None, annotated_frame\n","\n","\n","def compute_geometric_features(landmarks):\n","    landmarks_reshaped = landmarks.reshape(33, 4)\n","    coords = landmarks_reshaped[:, :3]\n","\n","    # Distancias\n","    key_pairs = [\n","        (11, 12), (11, 13), (13, 15), (12, 14), (14, 16),\n","        (11, 23), (12, 24), (23, 24), (23, 25), (25, 27),\n","        (24, 26), (26, 28), (27, 29), (29, 31), (28, 30),\n","        (30, 32), (15, 17), (16, 18), (0, 1)\n","    ]\n","\n","    distances = []\n","    for p1, p2 in key_pairs:\n","        dist = np.linalg.norm(coords[p1] - coords[p2])\n","        distances.append(dist)\n","\n","    # √Ångulos\n","    def calculate_angle(a, b, c):\n","        ba = a - b\n","        bc = c - b\n","        cosine = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n","        angle = np.arccos(np.clip(cosine, -1.0, 1.0))\n","        return np.degrees(angle)\n","\n","    angles = [\n","        calculate_angle(coords[11], coords[13], coords[15]),\n","        calculate_angle(coords[12], coords[14], coords[16]),\n","        calculate_angle(coords[13], coords[11], coords[23]),\n","        calculate_angle(coords[14], coords[12], coords[24]),\n","        calculate_angle(coords[11], coords[23], coords[25]),\n","        calculate_angle(coords[12], coords[24], coords[26]),\n","        calculate_angle(coords[23], coords[25], coords[27]),\n","        calculate_angle(coords[24], coords[26], coords[28]),\n","        calculate_angle(coords[25], coords[27], coords[29]),\n","        calculate_angle(coords[26], coords[28], coords[30]),\n","        calculate_angle(coords[11], coords[12], coords[24]),\n","        calculate_angle(coords[23], coords[24], coords[26]),\n","        calculate_angle(coords[27], coords[23], coords[11]),\n","        calculate_angle(coords[28], coords[24], coords[12]),\n","        calculate_angle(coords[15], coords[11], coords[12])\n","    ]\n","\n","    # Ratios\n","    torso_height = np.linalg.norm(coords[11] - coords[23])\n","    leg_length_left = np.linalg.norm(coords[23] - coords[27])\n","    leg_length_right = np.linalg.norm(coords[24] - coords[28])\n","    arm_length_left = np.linalg.norm(coords[11] - coords[15])\n","    arm_length_right = np.linalg.norm(coords[12] - coords[16])\n","\n","    ratios = [\n","        leg_length_left / (torso_height + 1e-6),\n","        leg_length_right / (torso_height + 1e-6),\n","        arm_length_left / (torso_height + 1e-6),\n","        arm_length_right / (torso_height + 1e-6),\n","        coords[23, 1] - coords[11, 1],\n","        coords[27, 1] - coords[23, 1],\n","        coords[15, 0] - coords[11, 0],\n","        coords[16, 0] - coords[12, 0],\n","        np.abs(coords[23, 0] - coords[24, 0]),\n","        np.abs(coords[11, 0] - coords[12, 0]),\n","        (coords[15, 1] + coords[16, 1]) / 2,\n","        (coords[27, 1] + coords[28, 1]) / 2,\n","        np.mean(coords[:, 1]),\n","        np.std(coords[:, 0]),\n","        np.std(coords[:, 1])\n","    ]\n","\n","    all_features = np.concatenate([landmarks, distances, angles, ratios])\n","    return all_features[:83].astype(np.float32)\n","\n","\n","def preprocess_and_predict(features):\n","    features_reshaped = features.reshape(1, -1)\n","    features_scaled = scaler.transform(features_reshaped)\n","    features_pca = pca.transform(features_scaled)\n","\n","    prediction = model.predict(features_pca)[0]\n","    probabilities_array = model.predict_proba(features_pca)[0]\n","\n","    predicted_class = label_encoder.inverse_transform([prediction])[0]\n","\n","    probabilities = {\n","        label_encoder.classes_[i]: prob\n","        for i, prob in enumerate(probabilities_array)\n","    }\n","\n","    confidence = probabilities_array.max()\n","\n","    return predicted_class, probabilities, confidence\n","\n","\n","def process_video(video_path, max_frames=300):\n","    print(f\"\\nüé• PROCESANDO: {video_path}\")\n","\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        return None, \"‚ùå Error abriendo video\", None\n","\n","    fps = int(cap.get(cv2.CAP_PROP_FPS))\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    print(f\"   üìä {width}x{height} @ {fps}fps, {total_frames} frames\")\n","\n","    frames_to_process = min(total_frames, max_frames)\n","    output_path = f'output_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.mp4'\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n","\n","    predictions_history = []\n","    frame_count = 0\n","\n","    while frame_count < frames_to_process:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        landmarks, annotated_frame = extract_landmarks(frame)\n","\n","        if landmarks is not None:\n","            features = compute_geometric_features(landmarks)\n","            predicted_class, probabilities, confidence = preprocess_and_predict(features)\n","\n","            predictions_history.append({\n","                'frame': frame_count,\n","                'activity': predicted_class,\n","                'confidence': confidence\n","            })\n","\n","            activity_text = predicted_class.replace('_', ' ').title()\n","            confidence_text = f\"{confidence*100:.1f}%\"\n","\n","            color = (0, 255, 0) if confidence > 0.9 else (0, 255, 255) if confidence > 0.7 else (0, 0, 255)\n","\n","            cv2.rectangle(annotated_frame, (10, 10), (width-10, 100), (0, 0, 0), -1)\n","            cv2.rectangle(annotated_frame, (10, 10), (width-10, 100), color, 3)\n","            cv2.putText(annotated_frame, f\"Actividad: {activity_text}\",\n","                       (20, 45), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n","            cv2.putText(annotated_frame, f\"Confianza: {confidence_text}\",\n","                       (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n","        else:\n","            cv2.putText(annotated_frame, \"No se detecta pose\",\n","                       (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","        out.write(annotated_frame)\n","        frame_count += 1\n","\n","        if frame_count % 30 == 0:\n","            print(f\"   ‚è≥ {frame_count}/{frames_to_process}...\")\n","\n","    cap.release()\n","    out.release()\n","\n","    print(f\"   ‚úÖ Procesado: {frame_count} frames\\n\")\n","\n","    if predictions_history:\n","        df = pd.DataFrame(predictions_history)\n","        most_common = df['activity'].mode()[0]\n","        most_common_pct = (df['activity'] == most_common).sum() / len(df) * 100\n","        avg_confidence = df['confidence'].mean() * 100\n","        activity_counts = df['activity'].value_counts()\n","\n","        summary_text = f\"\"\"\n","üìä RESUMEN\n","\n","üéØ Frames: {len(df)}\n","üèÜ Actividad: {most_common.replace('_', ' ').title()} ({most_common_pct:.1f}%)\n","üìà Confianza: {avg_confidence:.1f}%\n","\n","üìã Distribuci√≥n:\n","\"\"\"\n","        for activity, count in activity_counts.items():\n","            pct = count / len(df) * 100\n","            summary_text += f\"   ‚Ä¢ {activity.replace('_', ' ').title()}: {count} ({pct:.1f}%)\\n\"\n","\n","        # Gr√°fico\n","        avg_probs = {}\n","        for activity in label_encoder.classes_:\n","            activity_data = df[df['activity'] == activity]\n","            avg_probs[activity] = activity_data['confidence'].mean() if len(activity_data) > 0 else 0\n","\n","        fig, ax = plt.subplots(figsize=(10, 6))\n","        activities = [a.replace('_', ' ').title() for a in avg_probs.keys()]\n","        confidences = list(avg_probs.values())\n","\n","        bars = ax.barh(activities, confidences, color='skyblue')\n","        bars[confidences.index(max(confidences))].set_color('green')\n","\n","        ax.set_xlabel('Confianza Promedio')\n","        ax.set_title('Confianza por Actividad', fontweight='bold')\n","        ax.set_xlim(0, 1)\n","\n","        for i, v in enumerate(confidences):\n","            ax.text(v + 0.02, i, f'{v*100:.1f}%', va='center')\n","\n","        plt.tight_layout()\n","\n","        return output_path, summary_text, fig\n","\n","    return output_path, \"‚ö†Ô∏è Sin poses detectadas\", None\n","\n","\n","def gradio_interface(video):\n","    if video is None:\n","        return None, \"‚ö†Ô∏è Sube un video\", None\n","    return process_video(video, max_frames=300)\n","\n","print(\"‚úÖ Funciones listas\\n\")\n","\n","# ============================================\n","# LANZAR INTERFAZ\n","# ============================================\n","\n","print(\"üé® CREANDO INTERFAZ...\")\n","\n","interface = gr.Interface(\n","    fn=gradio_interface,\n","    inputs=gr.Video(label=\"üìπ Sube un video\"),\n","    outputs=[\n","        gr.Video(label=\"üé• Video Procesado\"),\n","        gr.Textbox(label=\"üìä Resumen\", lines=12),\n","        gr.Plot(label=\"üìà Gr√°fico\")\n","    ],\n","    title=\"üèÉ Clasificador de Actividades Humanas\",\n","    description=\"\"\"\n","    **MediaPipe + MLP (99% accuracy)**\n","\n","    Actividades: Caminar Hacia, Caminar Regreso, Girar, Ponerse de Pie, Sentarse\n","\n","    Sube un video corto (m√°x 10s) y espera el procesamiento.\n","    \"\"\",\n","    article=\"Desarrollado por Tom√°s Quintero - Universidad ICESI - Nov 2025\",\n","    cache_examples=False,\n","    allow_flagging=\"never\"\n",")\n","\n","print(\"=\" * 60)\n","print(\"üöÄ LANZANDO APLICACI√ìN...\")\n","print(\"=\" * 60)\n","\n","interface.launch(share=True, debug=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":965},"id":"tnvQCJiyelAW","executionInfo":{"status":"error","timestamp":1763680972206,"user_tz":300,"elapsed":64304,"user":{"displayName":"Tomas Quintero Gomez","userId":"11509027822852931188"}},"outputId":"f3e4eb39-7d49-4655-88d9-eff14fe965bf"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["üì¶ INSTALANDO DEPENDENCIAS...\n","============================================================\n","\u001b[33mWARNING: Skipping opencv-python-headless as it is not installed.\u001b[0m\u001b[33m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, which is not installed.\n","albucore 0.0.24 requires opencv-python-headless>=4.9.0.80, which is not installed.\n","dopamine-rl 4.1.2 requires opencv-python>=3.4.8.29, which is not installed.\n","dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\n","albumentations 2.0.8 requires opencv-python-headless>=4.9.0.80, which is not installed.\n","yfinance 0.2.66 requires websockets>=13.0, but you have websockets 12.0 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.5 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","dopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m‚úÖ Dependencias instaladas\n","‚ö†Ô∏è  Ignorar warnings de compatibilidad - el c√≥digo funcionar√°\n","\n","üìö IMPORTANDO LIBRER√çAS...\n","‚úÖ MediaPipe: 0.10.21\n","‚úÖ NumPy: 1.26.4\n","‚úÖ OpenCV: 4.11.0\n","\n","ü§ñ CARGANDO MODELO Y TRANSFORMERS...\n","============================================================\n","\n","üìÇ VERIFICANDO ARCHIVOS:\n","   ‚úÖ Modelo: best_model_mlp.pkl (230.76 KB)\n","   ‚úÖ Scaler: scaler.pkl (2.53 KB)\n","   ‚úÖ PCA: pca.pkl (12.38 KB)\n","   ‚úÖ Encoder: label_encoder.pkl (0.53 KB)\n","\n","üîÑ CARGANDO COMPONENTES...\n"]},{"output_type":"error","ename":"ValueError","evalue":"<class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2850428201.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nüîÑ CARGANDO COMPONENTES...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model_mlp.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   ‚úÖ Modelo MLP cargado\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0;31m# it has been written with. Other arrays are coerced to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m                 \u001b[0;31m# native endianness of the host system.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 749\u001b[0;31m                 obj = _unpickle(\n\u001b[0m\u001b[1;32m    750\u001b[0m                     \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m                     \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36m_unpickle\u001b[0;34m(fobj, ensure_native_byte_order, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             warnings.warn(\n","\u001b[0;32m/usr/lib/python3.12/pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1254\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m                 \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1256\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/pickle.py\u001b[0m in \u001b[0;36mload_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m         \u001b[0mstack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mREDUCE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m__bit_generator_ctor\u001b[0;34m(bit_generator_name)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mbit_gen_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbit_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mbit_generator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mBitGenerators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mbit_gen_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBitGenerators\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbit_generator\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         raise ValueError(\n","\u001b[0;31mValueError\u001b[0m: <class 'numpy.random._mt19937.MT19937'> is not a known BitGenerator module."]}]}]}