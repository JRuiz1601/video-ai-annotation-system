{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM8KTKfbKd0qnAPct+GiHnm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Y80ifY5shz3l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762119988760,"user_tz":300,"elapsed":5134,"user":{"displayName":"Tomas Quintero Gomez","userId":"11509027822852931188"}},"outputId":"83d639d8-feb9-40a5-ae2c-63bddd2ddfe8"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸ•µï¸ ANÃLISIS FORENSE - BÃšSQUEDA DE ERRORES CRÃTICOS\n","============================================================\n","ğŸ“Š VERIFICACIÃ“N BÃSICA DE DATOS:\n","   Train: 7,988 samples, 19 features\n","   Val: 1,707 samples, 19 features\n","   Test: 1,711 samples, 19 features\n","\n","ğŸ” PRUEBA 1 - BUSCAR DUPLICADOS ENTRE SETS:\n","   Train-Val overlap: 949 samples\n","   Train-Test overlap: 962 samples\n","   Val-Test overlap: 221 samples\n","   ğŸš¨ PROBLEMA DETECTADO: Data leakage entre sets!\n"]}],"source":["# ANÃLISIS FORENSE DEL MODELO - BUSCANDO PROBLEMAS\n","print(\"ğŸ•µï¸ ANÃLISIS FORENSE - BÃšSQUEDA DE ERRORES CRÃTICOS\")\n","print(\"=\" * 60)\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import accuracy_score\n","import joblib\n","\n","# Cargar todos los datasets\n","X_train = np.load('X_train.npy')\n","y_train = np.load('y_train.npy')\n","X_val = np.load('X_validation.npy')\n","y_val = np.load('y_validation.npy')\n","X_test = np.load('X_test.npy')\n","y_test = np.load('y_test.npy')\n","encoder = joblib.load('encoder.pkl')\n","\n","print(\"ğŸ“Š VERIFICACIÃ“N BÃSICA DE DATOS:\")\n","print(f\"   Train: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n","print(f\"   Val: {X_val.shape[0]:,} samples, {X_val.shape[1]} features\")\n","print(f\"   Test: {X_test.shape[0]:,} samples, {X_test.shape[1]} features\")\n","\n","# ğŸš¨ PRUEBA 1: Â¿HAY DUPLICADOS ENTRE SETS?\n","print(f\"\\nğŸ” PRUEBA 1 - BUSCAR DUPLICADOS ENTRE SETS:\")\n","\n","# Convertir a strings para comparaciÃ³n\n","X_train_str = [str(row) for row in X_train]\n","X_val_str = [str(row) for row in X_val]\n","X_test_str = [str(row) for row in X_test]\n","\n","train_val_overlap = len(set(X_train_str) & set(X_val_str))\n","train_test_overlap = len(set(X_train_str) & set(X_test_str))\n","val_test_overlap = len(set(X_val_str) & set(X_test_str))\n","\n","print(f\"   Train-Val overlap: {train_val_overlap} samples\")\n","print(f\"   Train-Test overlap: {train_test_overlap} samples\")\n","print(f\"   Val-Test overlap: {val_test_overlap} samples\")\n","\n","if train_val_overlap > 0 or train_test_overlap > 0 or val_test_overlap > 0:\n","    print(f\"   ğŸš¨ PROBLEMA DETECTADO: Data leakage entre sets!\")\n","else:\n","    print(f\"   âœ… Sin duplicados exactos entre sets\")\n"]},{"cell_type":"code","source":["# PRUEBA 2: ANALIZAR FEATURES SOSPECHOSAS\n","print(f\"\\nğŸ” PRUEBA 2 - ANÃLISIS DE FEATURES:\")\n","\n","# Â¿Hay features con varianza 0? (constantes)\n","feature_vars = np.var(X_train, axis=0)\n","zero_var_features = np.sum(feature_vars == 0)\n","print(f\"   Features con varianza 0: {zero_var_features}\")\n","\n","# Â¿Hay features con correlaciÃ³n perfecta con el target?\n","from scipy.stats import pearsonr\n","\n","print(f\"   CorrelaciÃ³n features vs target (top 5):\")\n","correlations = []\n","for i in range(X_train.shape[1]):\n","    corr, _ = pearsonr(X_train[:, i], y_train)\n","    correlations.append((i, abs(corr)))\n","\n","correlations.sort(key=lambda x: x[1], reverse=True)\n","for i, (feat_idx, corr) in enumerate(correlations[:5]):\n","    print(f\"      Feature {feat_idx}: r={corr:.3f}\")\n","    if corr > 0.95:\n","        print(f\"         ğŸš¨ SOSPECHOSO: CorrelaciÃ³n muy alta!\")\n","\n","# PRUEBA 3: DISTRIBUCION DE CLASES\n","print(f\"\\nğŸ” PRUEBA 3 - DISTRIBUCIÃ“N DE CLASES:\")\n","\n","def analyze_class_distribution(y, name):\n","    unique, counts = np.unique(y, return_counts=True)\n","    print(f\"   {name}:\")\n","    for cls, count in zip(unique, counts):\n","        class_name = encoder.classes_[cls]\n","        pct = count / len(y) * 100\n","        print(f\"      {class_name}: {count} ({pct:.1f}%)\")\n","\n","analyze_class_distribution(y_train, \"Train\")\n","analyze_class_distribution(y_val, \"Validation\")\n","analyze_class_distribution(y_test, \"Test\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UadU8-ztiW82","executionInfo":{"status":"ok","timestamp":1762120005936,"user_tz":300,"elapsed":73,"user":{"displayName":"Tomas Quintero Gomez","userId":"11509027822852931188"}},"outputId":"1896b489-481e-4319-9248-35eceb311e7a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ” PRUEBA 2 - ANÃLISIS DE FEATURES:\n","   Features con varianza 0: 0\n","   CorrelaciÃ³n features vs target (top 5):\n","      Feature 0: r=0.646\n","      Feature 6: r=0.385\n","      Feature 12: r=0.244\n","      Feature 11: r=0.175\n","      Feature 13: r=0.160\n","\n","ğŸ” PRUEBA 3 - DISTRIBUCIÃ“N DE CLASES:\n","   Train:\n","      caminar_hacia: 1725 (21.6%)\n","      caminar_regreso: 1659 (20.8%)\n","      girar: 1595 (20.0%)\n","      ponerse_pie: 1560 (19.5%)\n","      sentarse: 1449 (18.1%)\n","   Validation:\n","      caminar_hacia: 369 (21.6%)\n","      caminar_regreso: 354 (20.7%)\n","      girar: 341 (20.0%)\n","      ponerse_pie: 333 (19.5%)\n","      sentarse: 310 (18.2%)\n","   Test:\n","      caminar_hacia: 370 (21.6%)\n","      caminar_regreso: 355 (20.7%)\n","      girar: 342 (20.0%)\n","      ponerse_pie: 334 (19.5%)\n","      sentarse: 310 (18.1%)\n"]}]},{"cell_type":"code","source":["# PRUEBA 4: TEST DE OVERFITTING EXTREMO\n","print(f\"\\nğŸ” PRUEBA 4 - DETECTAR OVERFITTING SEVERO:\")\n","\n","# Crear modelo completamente nuevo desde cero\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# Modelo con arquitectura diferente\n","mlp_test = MLPClassifier(\n","    hidden_layer_sizes=(50,),  # MÃ¡s simple\n","    random_state=999,  # Seed diferente\n","    max_iter=500,\n","    alpha=0.01  # RegularizaciÃ³n\n",")\n","\n","print(f\"   Entrenando modelo nuevo con arquitectura diferente...\")\n","mlp_test.fit(X_train, y_train)\n","\n","# Evaluar\n","train_acc_new = accuracy_score(y_train, mlp_test.predict(X_train))\n","val_acc_new = accuracy_score(y_val, mlp_test.predict(X_val))\n","test_acc_new = accuracy_score(y_test, mlp_test.predict(X_test))\n","\n","print(f\"   NUEVO MODELO - Arquitectura mÃ¡s simple:\")\n","print(f\"      Train: {train_acc_new:.3f}\")\n","print(f\"      Val: {val_acc_new:.3f}\")\n","print(f\"      Test: {test_acc_new:.3f}\")\n","\n","# Cross-validation en datos originales\n","cv_scores = cross_val_score(mlp_test, X_train, y_train, cv=5)\n","print(f\"   CV Score: {cv_scores.mean():.3f} (Â±{cv_scores.std():.3f})\")\n","\n","if test_acc_new >= 0.95:\n","    print(f\"   ğŸ¤” SOSPECHOSO: Incluso modelo mÃ¡s simple da >95%\")\n","else:\n","    print(f\"   âœ… Modelo simple da accuracy mÃ¡s realista\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_s-Fa6jiaKv","executionInfo":{"status":"ok","timestamp":1762120040542,"user_tz":300,"elapsed":22157,"user":{"displayName":"Tomas Quintero Gomez","userId":"11509027822852931188"}},"outputId":"bb671828-a576-4241-b301-46c9074055ed"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ” PRUEBA 4 - DETECTAR OVERFITTING SEVERO:\n","   Entrenando modelo nuevo con arquitectura diferente...\n","   NUEVO MODELO - Arquitectura mÃ¡s simple:\n","      Train: 1.000\n","      Val: 0.998\n","      Test: 1.000\n","   CV Score: 0.998 (Â±0.001)\n","   ğŸ¤” SOSPECHOSO: Incluso modelo mÃ¡s simple da >95%\n"]}]},{"cell_type":"code","source":["# DIAGNÃ“STICO FINAL Y RECOMENDACIONES\n","print(f\"\\nğŸ¯ DIAGNÃ“STICO FINAL:\")\n","print(\"=\" * 30)\n","\n","issues_found = []\n","\n","# Verificar cada problema potencial\n","if train_val_overlap > 0 or train_test_overlap > 0:\n","    issues_found.append(\"Data leakage entre datasets\")\n","\n","if zero_var_features > 0:\n","    issues_found.append(f\"{zero_var_features} features constantes\")\n","\n","if any(corr > 0.95 for _, corr in correlations[:3]):\n","    issues_found.append(\"Features con correlaciÃ³n sospechosa\")\n","\n","if test_acc_new >= 0.98:\n","    issues_found.append(\"Modelo simple tambiÃ©n da accuracy muy alta\")\n","\n","print(f\"ğŸ” PROBLEMAS DETECTADOS:\")\n","if issues_found:\n","    for issue in issues_found:\n","        print(f\"   ğŸš¨ {issue}\")\n","else:\n","    print(f\"   âœ… Sin problemas evidentes detectados\")\n","\n","print(f\"\\nğŸ’¡ INTERPRETACIÃ“N:\")\n","if len(issues_found) == 0:\n","    print(f\"   ğŸ¯ El modelo parece legÃ­timo:\")\n","    print(f\"   â€¢ Sin duplicados entre datasets\")\n","    print(f\"   â€¢ Features con varianza normal\")\n","    print(f\"   â€¢ Sin correlaciones perfectas sospechosas\")\n","    print(f\"   â€¢ Problema realmente puede ser tan distintivo\")\n","\n","    verdict = \"MODELO PROBABLEMENTE LEGÃTIMO\"\n","    recommendation = \"Proceder con deployment, aÃ±adir monitoreo robusto\"\n","\n","elif len(issues_found) >= 2:\n","    print(f\"   ğŸš¨ MÃºltiples seÃ±ales de alarma:\")\n","    print(f\"   â€¢ Posible data leakage o error en pipeline\")\n","    print(f\"   â€¢ Revisar proceso de preparaciÃ³n de datos\")\n","\n","    verdict = \"MODELO SOSPECHOSO\"\n","    recommendation = \"REVISAR PIPELINE DE DATOS ANTES DE DEPLOYMENT\"\n","\n","else:\n","    print(f\"   ğŸ“Š SeÃ±ales mixtas:\")\n","    print(f\"   â€¢ Algunos indicadores preocupantes\")\n","    print(f\"   â€¢ Pero puede ser dataset genuinamente fÃ¡cil\")\n","\n","    verdict = \"PRECAUCIÃ“N RECOMENDADA\"\n","    recommendation = \"Deployment con monitoreo intensivo inicial\"\n","\n","print(f\"\\nğŸ† VEREDICTO: {verdict}\")\n","print(f\"ğŸ¯ RECOMENDACIÃ“N: {recommendation}\")\n"],"metadata":{"id":"jPdqLCJaiimm","executionInfo":{"status":"ok","timestamp":1762120054590,"user_tz":300,"elapsed":25,"user":{"displayName":"Tomas Quintero Gomez","userId":"11509027822852931188"}},"outputId":"4661fde1-080e-4a9f-b1bc-fbe57597a208","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","ğŸ¯ DIAGNÃ“STICO FINAL:\n","==============================\n","ğŸ” PROBLEMAS DETECTADOS:\n","   ğŸš¨ Data leakage entre datasets\n","   ğŸš¨ Modelo simple tambiÃ©n da accuracy muy alta\n","\n","ğŸ’¡ INTERPRETACIÃ“N:\n","   ğŸš¨ MÃºltiples seÃ±ales de alarma:\n","   â€¢ Posible data leakage o error en pipeline\n","   â€¢ Revisar proceso de preparaciÃ³n de datos\n","\n","ğŸ† VEREDICTO: MODELO SOSPECHOSO\n","ğŸ¯ RECOMENDACIÃ“N: REVISAR PIPELINE DE DATOS ANTES DE DEPLOYMENT\n"]}]}]}