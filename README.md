# Sistema de Anotaci√≥n de Video para An√°lisis de Actividades

Este proyecto es parte del curso **Inteligencia Artificial 1** de la Maestr√≠a en Inteligencia Artificial Aplicada, Universidad ICESI, Cali Colombia.

#### -- Estado del Proyecto: Activo

**L√≠der del Equipo: [Juan Esteban Ruiz](https://github.com/[github handle])(@slackHandle)**  

## Miembros del Equipo

|Nombre     |  Email   | 
|-----------|-----------------|
|[Juan Esteban Ruiz](https://github.com/JRuiz1601| juan.ruizome@u.icesi.edu.co |
|[Juan David Quintero](https://github.com/[github handle]| @juan.quintero |
|[Tomas Quintero](https://github.com/[github handle]) | @tomas.quintero |

## Contacto
* ¬°Puedes contactar al l√≠der del equipo o al instructor si tienes preguntas o est√°s interesado en contribuir!

## Introducci√≥n/Objetivo del Proyecto
El prop√≥sito de este proyecto es desarrollar un sistema automatizado de clasificaci√≥n de actividades humanas b√°sicas utilizando an√°lisis de coordenadas articulares extra√≠das mediante MediaPipe. El sistema identificar√° cinco actividades espec√≠ficas: caminar hacia la c√°mara, caminar de regreso, girar, sentarse y ponerse de pie, con una precisi√≥n superior al 85% y capacidad de procesamiento en tiempo real. Este desarrollo contribuye al avance de sistemas de an√°lisis de movimiento no invasivos aplicables en rehabilitaci√≥n, deporte e investigaci√≥n biomec√°nica.

### Metodolog√≠as Utilizadas
* An√°lisis Exploratorio de Datos (EDA)
* Aprendizaje Autom√°tico Supervisado
* Visualizaci√≥n de Datos
* Modelado Predictivo
* Procesamiento de Video en Tiempo Real
* Metodolog√≠a CRISP-DM
* Validaci√≥n Cruzada
* Feature Engineering

### Tecnolog√≠as
* Python 3.9
* MediaPipe (Google)
* OpenCV
* Scikit-learn
* XGBoost
* Pandas, NumPy
* Matplotlib, Seaborn
* Jupyter Notebooks
* Git/GitHub

## Descripci√≥n del Proyecto
Este sistema utiliza la biblioteca MediaPipe de Google para extraer coordenadas de 33 puntos clave articulares de videos en tiempo real. A partir de estas coordenadas (x,y,z,visibility), se entrenan modelos de clasificaci√≥n supervisada (SVM, Random Forest, XGBoost) para identificar autom√°ticamente las actividades realizadas.

**Fuentes de Datos**: Videos de personas realizando las 5 actividades espec√≠ficas, capturados desde diferentes √°ngulos, condiciones de iluminaci√≥n y velocidades. Dataset objetivo de 250+ videos con 20+ participantes diversos.

**An√°lisis y Modelado**: Extracci√≥n de caracter√≠sticas temporales y espaciales, normalizaci√≥n para diferentes tipos de cuerpo y distancias de c√°mara, entrenamiento de m√∫ltiples algoritmos con optimizaci√≥n de hiperpar√°metros y validaci√≥n cruzada.

**Desaf√≠os Principales**:
- Variabilidad en movimientos humanos entre diferentes usuarios
- Diferentes velocidades de ejecuci√≥n de actividades
- Oclusiones parciales y missing data en detecci√≥n de pose
- Generalizaci√≥n a nuevos usuarios no vistos durante entrenamiento
- Requisitos de tiempo real (<100ms por clasificaci√≥n)

## Comenzando
Instrucciones para contribuidores:

1. Clona este repositorio ([ayuda aqu√≠](https://help.github.com/articles/cloning-a-repository/)):
```
git clone https://github.com/[usuario]/sistema-anotacion-video-ia.git
cd sistema-anotacion-video-ia
```

2. Los datos sin procesar se mantienen en [`Entrega1/data/videos/`](./Entrega1/data/videos/) dentro de este repositorio.
   *Los videos originales se almacenan localmente debido a su tama√±o. Para obtener acceso, contacta al equipo.*

3. Los scripts de procesamiento/transformaci√≥n de datos est√°n en [`Entrega1/src/data/`](./Entrega1/src/data/)

4. Los notebooks de an√°lisis est√°n en [`Entrega1/notebooks/`](./Entrega1/notebooks/)

5. **Instalaci√≥n y Setup**:
```
cd Entrega1/
pip install -r requirements.txt
```

Para setup detallado, consulta las [instrucciones de instalaci√≥n](./Entrega1/docs/setup_instructions.md)

## Entregas y Documentaci√≥n Principal

### üìÇ Entrega 1 (Semana 12) - Fundamentos
* [Documento de Fundamentos](./Entrega1/docs/entrega1_fundamentos.md) - Preguntas, metodolog√≠a, m√©tricas y EDA
* [Setup MediaPipe](./Entrega1/notebooks/01_setup_mediapipe.ipynb) - Configuraci√≥n inicial del pipeline
* [EDA Inicial](./Entrega1/notebooks/02_eda_inicial.ipynb) - An√°lisis exploratorio de coordenadas

### üìÇ Entrega 2 (Semana 14) - Modelado
* [Entrenamiento de Modelos](./Entrega2/notebooks/model_training.ipynb)
* [Evaluaci√≥n Comparativa](./Entrega2/notebooks/model_evaluation.ipynb)
* [Optimizaci√≥n de Hiperpar√°metros](./Entrega2/notebooks/hyperparameter_tuning.ipynb)

### üìÇ Entrega 3 (Semana 17) - Despliegue
* [Sistema en Tiempo Real](./Entrega3/src/realtime_system.py)
* [Interfaz Gr√°fica](./Entrega3/src/gui_application.py)
* [Documentaci√≥n Final](./Entrega3/docs/reporte_final.pdf)

## Estado del Proyecto por Entregas

| Entrega | Estado | Fecha L√≠mite | Completitud |
|---------|--------|--------------|-------------|
| **Entrega 1** | ‚úÖ Completa | 13 octubre 2025 | 100% |
| **Entrega 2** | üîÑ En Progreso | 27 octubre 2025 | 0% |
| **Entrega 3** | ‚è≥ Planificada | 17 noviembre 2025 | 0% |

## M√©tricas Objetivo del Proyecto

- **Accuracy Global**: ‚â•85%
- **F1-Score por Clase**: ‚â•80% para cada actividad
- **Latencia de Inferencia**: <100ms por video
- **FPS en Tiempo Real**: ‚â•15 fps
- **Robustez Cross-Usuario**: ‚â•80% con usuarios no vistos

---

**Universidad ICESI** | **Facultad de Ingenier√≠a, Dise√±o y Ciencias Aplicadas** | **Inteligencia Artificial 1** | **2025-2**
